#!/usr/bin/env python3
"""
XGBoost ëª¨ë¸ ì „ìš© í›ˆë ¨ ë° ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš°
"""

import argparse
import gc
import json
import logging
import os
import psutil
import traceback
from datetime import datetime

import yaml
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, roc_auc_score

def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='XGBoost ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰')
    parser.add_argument('--config', type=str, default='config_xgboost.yaml',
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config_xgboost.yaml)')
    return parser.parse_args()

def load_config(config_path):
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"ğŸ“‹ ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
    return config

# ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹± ë° ì„¤ì • ë¡œë“œ
args = parse_args()
CFG = load_config(args.config)

from utils import seed_everything, get_device
from data_loader import load_train_data, load_test_data
from xgboost_model import create_xgboost_model

DEVICE = get_device()

def create_results_directory():
    """ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
    # datetime í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‹¤ì œ datetimeìœ¼ë¡œ êµì²´
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = CFG['PATHS']['RESULTS_DIR'].replace('{datetime}', timestamp)
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(results_dir, exist_ok=True)
    print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}")
    
    return results_dir

def train_xgboost_model(train_df, CFG, results_dir):
    """XGBoost ëª¨ë¸ í›ˆë ¨"""
    print(f"\nğŸš€ XGBoost ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    # ë°ì´í„° ë¶„í• 
    tr_df, va_df = train_test_split(train_df, test_size=CFG['VAL_SPLIT'], random_state=42, shuffle=True, stratify=train_df['clicked'])
    
    print(f"ğŸ“Š Stratified Split ê²°ê³¼:")
    print(f"   â€¢ ì „ì²´ ë°ì´í„°: {len(train_df):,}ê°œ (clicked=0: {len(train_df[train_df['clicked']==0]):,}ê°œ, clicked=1: {len(train_df[train_df['clicked']==1]):,}ê°œ)")
    print(f"   â€¢ í›ˆë ¨ ë°ì´í„°: {len(tr_df):,}ê°œ (clicked=0: {len(tr_df[tr_df['clicked']==0]):,}ê°œ, clicked=1: {len(tr_df[tr_df['clicked']==1]):,}ê°œ)")
    print(f"   â€¢ ê²€ì¦ ë°ì´í„°: {len(va_df):,}ê°œ (clicked=0: {len(va_df[va_df['clicked']==0]):,}ê°œ, clicked=1: {len(va_df[va_df['clicked']==1]):,}ê°œ)")
    
    # í´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸
    train_ratio_0 = len(tr_df[tr_df['clicked']==0]) / len(tr_df)
    train_ratio_1 = len(tr_df[tr_df['clicked']==1]) / len(tr_df)
    val_ratio_0 = len(va_df[va_df['clicked']==0]) / len(va_df)
    val_ratio_1 = len(va_df[va_df['clicked']==1]) / len(va_df)
    print(f"   â€¢ í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤ ë¹„ìœ¨: clicked=0 ({train_ratio_0:.3f}), clicked=1 ({train_ratio_1:.3f})")
    print(f"   â€¢ ê²€ì¦ ë°ì´í„° í´ë˜ìŠ¤ ë¹„ìœ¨: clicked=0 ({val_ratio_0:.3f}), clicked=1 ({val_ratio_1:.3f})")
    
    # í”¼ì²˜ ë¶„ë¦¬ (ì‹œí€€ìŠ¤ í”¼ì²˜ ì œì™¸)
    categorical_features = CFG['MODEL']['FEATURES']['CATEGORICAL']
    excluded_features = CFG['MODEL']['FEATURES']['EXCLUDED']
    
    # ìˆ˜ì¹˜í˜• í”¼ì²˜ëŠ” ë²”ì£¼í˜•ê³¼ ì œì™¸ í”¼ì²˜ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€
    numerical_features = [col for col in train_df.columns 
                         if col not in categorical_features 
                         and col not in excluded_features
                         and col not in ['clicked', 'id']]
    
    print(f"ğŸ“Š í”¼ì²˜ ì •ë³´:")
    print(f"   â€¢ ë²”ì£¼í˜• í”¼ì²˜: {len(categorical_features)}ê°œ")
    print(f"   â€¢ ìˆ˜ì¹˜í˜• í”¼ì²˜: {len(numerical_features)}ê°œ")
    print(f"   â€¢ ì‹œí€€ìŠ¤ í”¼ì²˜: ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (XGBoost)")
    print(f"   â€¢ ì œì™¸ í”¼ì²˜: {excluded_features}")
    
    # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
    train_categorical = tr_df[categorical_features] if categorical_features else None
    train_numerical = tr_df[numerical_features] if numerical_features else None
    train_y = tr_df['clicked'].values
    
    # ê²€ì¦ ë°ì´í„° ì¤€ë¹„
    val_categorical = va_df[categorical_features] if categorical_features else None
    val_numerical = va_df[numerical_features] if numerical_features else None
    val_y = va_df['clicked'].values
    
    # XGBoost ëª¨ë¸ ìƒì„±
    xgb_config = CFG['MODEL']['XGBOOST']
    xgb_params = {
        'n_estimators': xgb_config['N_ESTIMATORS'],
        'max_depth': xgb_config['MAX_DEPTH'],
        'learning_rate': xgb_config['LEARNING_RATE'],
        'subsample': xgb_config['SUBSAMPLE'],
        'colsample_bytree': xgb_config['COLSAMPLE_BYTREE'],
        'reg_alpha': xgb_config['REG_ALPHA'],
        'reg_lambda': xgb_config['REG_LAMBDA'],
        'random_state': xgb_config['RANDOM_STATE'],
        'n_jobs': xgb_config['N_JOBS'],
        'early_stopping_rounds': xgb_config['EARLY_STOPPING_ROUNDS'],
        'eval_metric': xgb_config['EVAL_METRIC']
    }
    
    model = create_xgboost_model(xgb_params)
    
    print(f"ğŸ”§ XGBoost ëª¨ë¸ ì„¤ì •:")
    print(f"   â€¢ N Estimators: {xgb_params['n_estimators']}")
    print(f"   â€¢ Max Depth: {xgb_params['max_depth']}")
    print(f"   â€¢ Learning Rate: {xgb_params['learning_rate']}")
    print(f"   â€¢ Subsample: {xgb_params['subsample']}")
    print(f"   â€¢ Colsample By Tree: {xgb_params['colsample_bytree']}")
    print(f"   â€¢ Reg Alpha: {xgb_params['reg_alpha']}")
    print(f"   â€¢ Reg Lambda: {xgb_params['reg_lambda']}")
    print(f"   â€¢ Early Stopping Rounds: {xgb_params['early_stopping_rounds']}")
    print(f"   â€¢ Random State: {xgb_params['random_state']}")
    print(f"   â€¢ N Jobs: {xgb_params['n_jobs']}")
    
    # ëª¨ë¸ í›ˆë ¨
    print(f"ğŸš€ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
    model.fit(
        X_categorical=train_categorical,
        X_numerical=train_numerical,
        y=train_y,
        X_val_categorical=val_categorical,
        X_val_numerical=val_numerical,
        y_val=val_y
    )
    
    # ê²€ì¦ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€
    print(f"ğŸ“Š ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    val_predictions = model.predict(
        X_categorical=val_categorical,
        X_numerical=val_numerical
    )
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    val_rmse = np.sqrt(mean_squared_error(val_y, val_predictions))
    
    # AUC ê³„ì‚°ì„ ìœ„í•´ sigmoid ì ìš©
    val_probs = 1 / (1 + np.exp(-val_predictions))  # sigmoid
    val_auc = roc_auc_score(val_y, val_probs)
    
    print(f"âœ… XGBoost í›ˆë ¨ ì™„ë£Œ!")
    print(f"   â€¢ ê²€ì¦ RMSE: {val_rmse:.6f}")
    print(f"   â€¢ ê²€ì¦ AUC: {val_auc:.6f}")
    
    # ëª¨ë¸ ì €ì¥
    model_path = os.path.join(results_dir, "xgboost_model.pkl")
    model.save(model_path)
    print(f"ğŸ’¾ XGBoost ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
    
    return model, categorical_features, numerical_features

def predict_xgboost_model(test_df, model, categorical_features, numerical_features, CFG, results_dir):
    """XGBoost ëª¨ë¸ ì˜ˆì¸¡"""
    print(f"\nğŸ”® XGBoost ëª¨ë¸ ì˜ˆì¸¡ ì‹œì‘...")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    test_categorical = test_df[categorical_features] if categorical_features else None
    test_numerical = test_df[numerical_features] if numerical_features else None
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°:")
    print(f"   â€¢ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(test_df):,}ê°œ")
    print(f"   â€¢ ë²”ì£¼í˜• í”¼ì²˜: {len(categorical_features)}ê°œ")
    print(f"   â€¢ ìˆ˜ì¹˜í˜• í”¼ì²˜: {len(numerical_features)}ê°œ")
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    print(f"ğŸ”® ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    predictions = model.predict(
        X_categorical=test_categorical,
        X_numerical=test_numerical
    )
    
    # sigmoid ì ìš©í•˜ì—¬ í™•ë¥ ë¡œ ë³€í™˜
    probabilities = 1 / (1 + np.exp(-predictions))
    
    print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:")
    print(f"   â€¢ Shape: {probabilities.shape}")
    print(f"   â€¢ Min: {probabilities.min():.4f}")
    print(f"   â€¢ Max: {probabilities.max():.4f}")
    print(f"   â€¢ Mean: {probabilities.mean():.4f}")
    print(f"   â€¢ Std: {probabilities.std():.4f}")
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission_df = pd.DataFrame({
        'id': test_df['id'],
        'clicked': probabilities
    })
    
    submission_path = os.path.join(results_dir, f"xgboost_submission_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
    submission_df.to_csv(submission_path, index=False)
    print(f"ğŸ’¾ ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_path}")
    
    return submission_df

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸš€ XGBoost ëª¨ë¸ í›ˆë ¨ ë° ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
        print("=" * 60)
        
        # ì‹œë“œ ì„¤ì •
        seed_everything(CFG['SEED'])
        print(f"ğŸ² ì‹œë“œ ì„¤ì •: {CFG['SEED']}")
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        results_dir = create_results_directory()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        memory_info = psutil.virtual_memory()
        print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_info.percent:.1f}% ({memory_info.used / 1024**3:.1f}GB / {memory_info.total / 1024**3:.1f}GB)")
        
        # í›ˆë ¨ ë°ì´í„° ë¡œë“œ
        print(f"\nğŸ“Š í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì¤‘...")
        train_df = load_train_data(CFG['PATHS']['TRAIN_DATA'])
        print(f"   â€¢ í›ˆë ¨ ë°ì´í„° í¬ê¸°: {train_df.shape}")
        print(f"   â€¢ í´ë˜ìŠ¤ ë¶„í¬: {train_df['clicked'].value_counts().to_dict()}")
        
        # XGBoost ëª¨ë¸ í›ˆë ¨
        model, categorical_features, numerical_features = train_xgboost_model(train_df, CFG, results_dir)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del train_df
        gc.collect()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        test_df = load_test_data(CFG['PATHS']['TEST_DATA'])
        print(f"   â€¢ í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {test_df.shape}")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        submission_df = predict_xgboost_model(test_df, model, categorical_features, numerical_features, CFG, results_dir)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'model_type': 'xgboost',
            'config': CFG,
            'categorical_features': categorical_features,
            'numerical_features': numerical_features,
            'timestamp': datetime.now().isoformat(),
            'submission_shape': submission_df.shape
        }
        
        metadata_path = os.path.join(results_dir, f"metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {metadata_path}")
        
        print("\nğŸ‰ XGBoost ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {results_dir}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
