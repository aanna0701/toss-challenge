#!/usr/bin/env python3
"""
NVIDIA Merlinì„ í™œìš©í•œ ê³ ì„±ëŠ¥ ë°ì´í„°ë¡œë”
ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ìµœì í™”ëœ ë°ì´í„°ë¡œë”© ì‹œìŠ¤í…œ
"""

import json
import os
import warnings
from typing import Tuple, Dict, List, Optional, Union
import logging

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

# NVIDIA Merlin imports
try:
    import nvtabular as nvt
    from nvtabular import ops
    from nvtabular.ops import Normalize, FillMissing, Categorify, AddMetadata
    from nvtabular.workflow import Workflow
    from nvtabular.io import ParquetDataset
    from nvtabular.utils import device_mem_size, get_rmm_size
    import cudf
    import cupy as cp
    MERLIN_AVAILABLE = True
except ImportError:
    MERLIN_AVAILABLE = False
    warnings.warn("NVIDIA Merlin not available. Falling back to standard PyTorch DataLoader.")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MerlinFeatureProcessor:
    """NVIDIA Merlin ê¸°ë°˜ í”¼ì²˜ ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Dict, normalization_stats_path: str, use_merlin: bool = True):
        self.config = config
        self.use_merlin = use_merlin and MERLIN_AVAILABLE
        self.normalization_stats_path = normalization_stats_path
        
        # í”¼ì²˜ ë¶„ë¥˜
        self.categorical_features = self.config['MODEL']['FEATURES']['CATEGORICAL']
        self.sequential_feature = self.config['MODEL']['FEATURES']['SEQUENTIAL']
        self.excluded_features = self.config['MODEL']['FEATURES']['EXCLUDED']
        
        # Merlin ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
        self.workflow = None
        self.categorical_cardinalities = {}
        self.numerical_features = []
        
        if self.use_merlin:
            logger.info("ğŸš€ NVIDIA Merlin í”¼ì²˜ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”")
            self._setup_merlin_workflow()
        else:
            logger.info("âš ï¸  NVIDIA Merlin ì‚¬ìš© ë¶ˆê°€. í‘œì¤€ í”¼ì²˜ í”„ë¡œì„¸ì„œ ì‚¬ìš©")
            self._load_normalization_stats()
    
    def _setup_merlin_workflow(self):
        """Merlin ì›Œí¬í”Œë¡œìš° ì„¤ì •"""
        try:
            # GPU ë©”ëª¨ë¦¬ ì„¤ì •
            device_mem = device_mem_size()
            logger.info(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {device_mem / 1024**3:.2f} GB")
            
            # í”¼ì²˜ ì •ì˜
            categorical_cols = self.categorical_features
            numerical_cols = self._get_numerical_features()
            
            logger.info(f"ğŸ“Š ë²”ì£¼í˜• í”¼ì²˜: {len(categorical_cols)}ê°œ")
            logger.info(f"ğŸ“Š ìˆ˜ì¹˜í˜• í”¼ì²˜: {len(numerical_cols)}ê°œ")
            
            # Merlin ì›Œí¬í”Œë¡œìš° êµ¬ì„±
            categorical_ops = [
                ops.FillMissing(fill_val=0),
                ops.Categorify()
            ]
            
            numerical_ops = [
                ops.FillMissing(fill_val=0.0),
                ops.Normalize()
            ]
            
            # ì›Œí¬í”Œë¡œìš° ìƒì„±
            self.workflow = Workflow(
                categorical_cols >> categorical_ops,
                numerical_cols >> numerical_ops
            )
            
            logger.info("âœ… Merlin ì›Œí¬í”Œë¡œìš° ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Merlin ì›Œí¬í”Œë¡œìš° ì„¤ì • ì‹¤íŒ¨: {e}")
            self.use_merlin = False
            self._load_normalization_stats()
    
    def _get_numerical_features(self) -> List[str]:
        """ìˆ˜ì¹˜í˜• í”¼ì²˜ ëª©ë¡ ìƒì„±"""
        # ì „ì²´ í”¼ì²˜ì—ì„œ ë²”ì£¼í˜•, ì‹œí€€ìŠ¤, ì œì™¸ í”¼ì²˜ë¥¼ ì œì™¸
        exclude_cols = set(
            self.categorical_features + 
            [self.sequential_feature, 'ID', 'clicked'] + 
            self.excluded_features
        )
        
        # ì‹¤ì œ ë°ì´í„°ì—ì„œ í”¼ì²˜ í™•ì¸ (ì„ì‹œë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜, fitì—ì„œ ì‹¤ì œ ì„¤ì •)
        return []
    
    def _load_normalization_stats(self):
        """í‘œì¤€í™” í†µê³„ ë¡œë“œ (Merlin ì‚¬ìš© ë¶ˆê°€ ì‹œ)"""
        try:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            norm_stats_full_path = os.path.join(script_dir, self.normalization_stats_path)
            
            with open(norm_stats_full_path, 'r', encoding='utf-8') as f:
                self.norm_stats = json.load(f)['statistics']
            
            logger.info("âœ… í‘œì¤€í™” í†µê³„ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ í‘œì¤€í™” í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.norm_stats = {}
    
    def fit(self, df: pd.DataFrame) -> 'MerlinFeatureProcessor':
        """ë°ì´í„°ì— ë§ì¶° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í•™ìŠµ"""
        logger.info(f"ğŸ”§ í”¼ì²˜ í”„ë¡œì„¸ì„œ í•™ìŠµ ì‹œì‘: {df.shape}")
        
        if self.use_merlin:
            self._fit_merlin(df)
        else:
            self._fit_standard(df)
        
        logger.info("âœ… í”¼ì²˜ í”„ë¡œì„¸ì„œ í•™ìŠµ ì™„ë£Œ")
        return self
    
    def _fit_merlin(self, df: pd.DataFrame):
        """Merlin ê¸°ë°˜ í•™ìŠµ"""
        try:
            # cuDFë¡œ ë³€í™˜
            if isinstance(df, pd.DataFrame):
                df_cudf = cudf.from_pandas(df)
            else:
                df_cudf = df
            
            # ìˆ˜ì¹˜í˜• í”¼ì²˜ ì—…ë°ì´íŠ¸
            self.numerical_features = self._get_numerical_features_from_df(df)
            
            # ì›Œí¬í”Œë¡œìš° ì¬ì„¤ì •
            categorical_cols = self.categorical_features
            numerical_cols = self.numerical_features
            
            categorical_ops = [
                ops.FillMissing(fill_val=0),
                ops.Categorify()
            ]
            
            numerical_ops = [
                ops.FillMissing(fill_val=0.0),
                ops.Normalize()
            ]
            
            self.workflow = Workflow(
                categorical_cols >> categorical_ops,
                numerical_cols >> numerical_ops
            )
            
            # ì›Œí¬í”Œë¡œìš° í•™ìŠµ
            self.workflow.fit(df_cudf)
            
            # ì¹´ë””ë„ë¦¬í‹° ì •ë³´ ì¶”ì¶œ
            for col in categorical_cols:
                if col in df.columns:
                    unique_vals = df[col].dropna().nunique()
                    self.categorical_cardinalities[col] = unique_vals + 1  # +1 for missing
            
            logger.info(f"ğŸ“Š Merlin í•™ìŠµ ì™„ë£Œ - ë²”ì£¼í˜•: {len(categorical_cols)}, ìˆ˜ì¹˜í˜•: {len(numerical_cols)}")
            
        except Exception as e:
            logger.error(f"âŒ Merlin í•™ìŠµ ì‹¤íŒ¨: {e}")
            self.use_merlin = False
            self._fit_standard(df)
    
    def _fit_standard(self, df: pd.DataFrame):
        """í‘œì¤€ PyTorch ê¸°ë°˜ í•™ìŠµ"""
        # ë²”ì£¼í˜• í”¼ì²˜ ì¹´ë””ë„ë¦¬í‹° ê³„ì‚°
        for feat in self.categorical_features:
            if feat in df.columns:
                unique_vals = df[feat].dropna().nunique()
                self.categorical_cardinalities[feat] = unique_vals + 1  # +1 for missing
        
        # ìˆ˜ì¹˜í˜• í”¼ì²˜ ëª©ë¡ ìƒì„±
        exclude_cols = set(
            self.categorical_features + 
            [self.sequential_feature, 'ID', 'clicked'] + 
            self.excluded_features
        )
        self.numerical_features = [col for col in df.columns if col not in exclude_cols]
        
        logger.info(f"ğŸ“Š í‘œì¤€ í•™ìŠµ ì™„ë£Œ - ë²”ì£¼í˜•: {len(self.categorical_features)}, ìˆ˜ì¹˜í˜•: {len(self.numerical_features)}")
    
    def _get_numerical_features_from_df(self, df: pd.DataFrame) -> List[str]:
        """ë°ì´í„°í”„ë ˆì„ì—ì„œ ìˆ˜ì¹˜í˜• í”¼ì²˜ ì¶”ì¶œ"""
        exclude_cols = set(
            self.categorical_features + 
            [self.sequential_feature, 'ID', 'clicked'] + 
            self.excluded_features
        )
        return [col for col in df.columns if col not in exclude_cols]
    
    def transform(self, df: pd.DataFrame) -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:
        """ë°ì´í„° ë³€í™˜"""
        if self.use_merlin:
            return self._transform_merlin(df)
        else:
            return self._transform_standard(df)
    
    def _transform_merlin(self, df: pd.DataFrame) -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:
        """Merlin ê¸°ë°˜ ë³€í™˜"""
        try:
            # cuDFë¡œ ë³€í™˜
            if isinstance(df, pd.DataFrame):
                df_cudf = cudf.from_pandas(df)
            else:
                df_cudf = df
            
            # Merlin ì›Œí¬í”Œë¡œìš° ì ìš©
            transformed = self.workflow.transform(df_cudf)
            
            # ë²”ì£¼í˜• í”¼ì²˜ ì¶”ì¶œ
            categorical_data = []
            for feat in self.categorical_features:
                if feat in transformed.columns:
                    cat_data = transformed[feat].values.get()  # GPUì—ì„œ CPUë¡œ
                    categorical_data.append(cat_data)
            
            if categorical_data:
                x_categorical = torch.tensor(np.column_stack(categorical_data), dtype=torch.long)
            else:
                x_categorical = torch.empty(len(df), 0, dtype=torch.long)
            
            # ìˆ˜ì¹˜í˜• í”¼ì²˜ ì¶”ì¶œ
            numerical_data = []
            for feat in self.numerical_features:
                if feat in transformed.columns:
                    num_data = transformed[feat].values.get()  # GPUì—ì„œ CPUë¡œ
                    numerical_data.append(num_data)
            
            if numerical_data:
                x_numerical = torch.tensor(np.column_stack(numerical_data), dtype=torch.float32)
            else:
                x_numerical = torch.empty(len(df), 0, dtype=torch.float32)
            
            # ì‹œí€€ìŠ¤ í”¼ì²˜ ì²˜ë¦¬ (Merlinì—ì„œëŠ” ë³„ë„ ì²˜ë¦¬)
            sequences = self._process_sequences(df)
            
            return x_categorical, x_numerical, sequences
            
        except Exception as e:
            logger.error(f"âŒ Merlin ë³€í™˜ ì‹¤íŒ¨: {e}")
            return self._transform_standard(df)
    
    def _transform_standard(self, df: pd.DataFrame) -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:
        """í‘œì¤€ PyTorch ê¸°ë°˜ ë³€í™˜"""
        batch_size = len(df)
        
        # ë²”ì£¼í˜• í”¼ì²˜ ì²˜ë¦¬
        categorical_data = []
        for feat in self.categorical_features:
            if feat in df.columns:
                # ê°„ë‹¨í•œ ë¼ë²¨ ì¸ì½”ë”© (0ë¶€í„° ì‹œì‘)
                unique_vals = df[feat].dropna().unique()
                val_to_idx = {val: idx + 1 for idx, val in enumerate(sorted(unique_vals))}
                encoded = df[feat].map(val_to_idx).fillna(0).astype(int)
                categorical_data.append(encoded.values)
        
        if categorical_data:
            x_categorical = torch.tensor(np.column_stack(categorical_data), dtype=torch.long)
        else:
            x_categorical = torch.empty(batch_size, 0, dtype=torch.long)
        
        # ìˆ˜ì¹˜í˜• í”¼ì²˜ ì²˜ë¦¬ (í‘œì¤€í™”)
        numerical_data = []
        for feat in self.numerical_features:
            if feat in df.columns:
                if feat in self.norm_stats:
                    mean = self.norm_stats[feat]['mean']
                    std = self.norm_stats[feat]['std']
                    feat_data = pd.to_numeric(df[feat], errors='coerce')
                    standardized = (feat_data - mean) / std
                    standardized = standardized.fillna(0)
                    numerical_data.append(standardized.values.astype(np.float32))
                else:
                    # í‘œì¤€í™” í†µê³„ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê°’ ì‚¬ìš©
                    feat_data = pd.to_numeric(df[feat], errors='coerce').fillna(0)
                    numerical_data.append(feat_data.values.astype(np.float32))
        
        if numerical_data:
            x_numerical = torch.tensor(np.column_stack(numerical_data), dtype=torch.float32)
        else:
            x_numerical = torch.empty(batch_size, 0, dtype=torch.float32)
        
        # ì‹œí€€ìŠ¤ í”¼ì²˜ ì²˜ë¦¬
        sequences = self._process_sequences(df)
        
        return x_categorical, x_numerical, sequences
    
    def _process_sequences(self, df: pd.DataFrame) -> List[torch.Tensor]:
        """ì‹œí€€ìŠ¤ í”¼ì²˜ ì²˜ë¦¬"""
        if self.sequential_feature not in df.columns:
            return [torch.tensor([0.0], dtype=torch.float32) for _ in range(len(df))]
        
        seq_strings = df[self.sequential_feature].astype(str).values
        sequences = []
        
        for s in seq_strings:
            if s and s != 'nan':
                try:
                    arr = np.fromstring(s, sep=",", dtype=np.float32)
                    if arr.size == 0:
                        arr = np.array([0.0], dtype=np.float32)
                except:
                    arr = np.array([0.0], dtype=np.float32)
            else:
                arr = np.array([0.0], dtype=np.float32)
            
            sequences.append(torch.from_numpy(arr))
        
        return sequences
    
    def save(self, filepath: str):
        """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì €ì¥"""
        save_data = {
            'config': self.config,
            'categorical_features': self.categorical_features,
            'sequential_feature': self.sequential_feature,
            'excluded_features': self.excluded_features,
            'categorical_cardinalities': self.categorical_cardinalities,
            'numerical_features': self.numerical_features,
            'use_merlin': self.use_merlin,
            'norm_stats': getattr(self, 'norm_stats', {})
        }
        
        torch.save(save_data, filepath)
        logger.info(f"ğŸ’¾ í”¼ì²˜ í”„ë¡œì„¸ì„œ ì €ì¥ ì™„ë£Œ: {filepath}")
    
    def load(self, filepath: str):
        """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë¡œë“œ"""
        save_data = torch.load(filepath, map_location='cpu')
        
        self.config = save_data['config']
        self.categorical_features = save_data['categorical_features']
        self.sequential_feature = save_data['sequential_feature']
        self.excluded_features = save_data['excluded_features']
        self.categorical_cardinalities = save_data['categorical_cardinalities']
        self.numerical_features = save_data['numerical_features']
        self.use_merlin = save_data.get('use_merlin', False)
        self.norm_stats = save_data.get('norm_stats', {})
        
        logger.info(f"ğŸ“‚ í”¼ì²˜ í”„ë¡œì„¸ì„œ ë¡œë“œ ì™„ë£Œ: {filepath}")


class MerlinClickDataset(Dataset):
    """NVIDIA Merlin ê¸°ë°˜ ê³ ì„±ëŠ¥ ë°ì´í„°ì…‹"""
    
    def __init__(self, 
                 df: pd.DataFrame, 
                 feature_processor: MerlinFeatureProcessor,
                 target_col: str = 'clicked',
                 has_target: bool = True,
                 has_id: bool = False,
                 use_merlin: bool = True):
        
        self.df = df.reset_index(drop=True)
        self.feature_processor = feature_processor
        self.target_col = target_col
        self.has_target = has_target
        self.has_id = has_id
        self.use_merlin = use_merlin and MERLIN_AVAILABLE
        
        logger.info(f"ğŸ“Š Merlin ë°ì´í„°ì…‹ ì´ˆê¸°í™”: {self.df.shape}")
        
        # í”¼ì²˜ ì²˜ë¦¬
        if self.use_merlin:
            self._process_with_merlin()
        else:
            self._process_with_standard()
    
    def _process_with_merlin(self):
        """Merlin ê¸°ë°˜ ì²˜ë¦¬"""
        try:
            # cuDFë¡œ ë³€í™˜
            df_cudf = cudf.from_pandas(self.df)
            
            # Merlin ì›Œí¬í”Œë¡œìš° ì ìš©
            transformed = self.feature_processor.workflow.transform(df_cudf)
            
            # ë²”ì£¼í˜• í”¼ì²˜ ì²˜ë¦¬
            self.x_categorical = self._extract_categorical_features(transformed)
            
            # ìˆ˜ì¹˜í˜• í”¼ì²˜ ì²˜ë¦¬
            self.x_numerical = self._extract_numerical_features(transformed)
            
            # ì‹œí€€ìŠ¤ í”¼ì²˜ ì²˜ë¦¬
            self.sequences = self.feature_processor._process_sequences(self.df)
            
            logger.info("âœ… Merlin ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Merlin ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            self.use_merlin = False
            self._process_with_standard()
    
    def _process_with_standard(self):
        """í‘œì¤€ PyTorch ê¸°ë°˜ ì²˜ë¦¬"""
        self.x_categorical, self.x_numerical, self.sequences = self.feature_processor.transform(self.df)
        
        if self.has_target:
            self.y = self.df[self.target_col].astype(np.float32).values
        
        logger.info("âœ… í‘œì¤€ ê¸°ë°˜ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")
    
    def _extract_categorical_features(self, transformed_df) -> torch.Tensor:
        """ë²”ì£¼í˜• í”¼ì²˜ ì¶”ì¶œ"""
        categorical_data = []
        for feat in self.feature_processor.categorical_features:
            if feat in transformed_df.columns:
                cat_data = transformed_df[feat].values.get()  # GPUì—ì„œ CPUë¡œ
                categorical_data.append(cat_data)
        
        if categorical_data:
            return torch.tensor(np.column_stack(categorical_data), dtype=torch.long)
        else:
            return torch.empty(len(self.df), 0, dtype=torch.long)
    
    def _extract_numerical_features(self, transformed_df) -> torch.Tensor:
        """ìˆ˜ì¹˜í˜• í”¼ì²˜ ì¶”ì¶œ"""
        numerical_data = []
        for feat in self.feature_processor.numerical_features:
            if feat in transformed_df.columns:
                num_data = transformed_df[feat].values.get()  # GPUì—ì„œ CPUë¡œ
                numerical_data.append(num_data)
        
        if numerical_data:
            return torch.tensor(np.column_stack(numerical_data), dtype=torch.float32)
        else:
            return torch.empty(len(self.df), 0, dtype=torch.float32)
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        item = {
            'x_categorical': self.x_categorical[idx],
            'x_numerical': self.x_numerical[idx],
            'seq': self.sequences[idx]
        }
        
        if self.has_id:
            if 'ID' not in self.df.columns:
                raise ValueError("âŒ IDê°€ í•„ìš”í•œë° ë°ì´í„°ì— 'ID' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            item['id'] = self.df.iloc[idx]['ID']
        
        if self.has_target:
            y = torch.tensor(self.y[idx], dtype=torch.float)
            item['y'] = y
        
        return item


def create_merlin_dataloader(dataset: MerlinClickDataset, 
                           batch_size: int = 2048,
                           shuffle: bool = True,
                           num_workers: int = 4,
                           pin_memory: bool = True) -> DataLoader:
    """Merlin ê¸°ë°˜ ê³ ì„±ëŠ¥ DataLoader ìƒì„±"""
    
    collate_fn = collate_fn_merlin_train if dataset.has_target else collate_fn_merlin_infer
    
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=pin_memory,
        collate_fn=collate_fn,
        persistent_workers=True if num_workers > 0 else False
    )


def collate_fn_merlin_train(batch):
    """Merlin ê¸°ë°˜ í›ˆë ¨ collate í•¨ìˆ˜"""
    x_categorical = [item['x_categorical'] for item in batch]
    x_numerical = [item['x_numerical'] for item in batch]
    seqs = [item['seq'] for item in batch]
    ys = [item['y'] for item in batch]
    
    # ìŠ¤íƒìœ¼ë¡œ ë³€í™˜
    x_categorical = torch.stack(x_categorical)
    x_numerical = torch.stack(x_numerical)
    ys = torch.stack(ys)
    
    # ì‹œí€€ìŠ¤ íŒ¨ë”©
    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)
    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)
    seq_lengths = torch.clamp(seq_lengths, min=1)
    
    return {
        'x_categorical': x_categorical,
        'x_numerical': x_numerical,
        'seqs': seqs_padded,
        'seq_lengths': seq_lengths,
        'ys': ys
    }


def collate_fn_merlin_infer(batch):
    """Merlin ê¸°ë°˜ ì¶”ë¡  collate í•¨ìˆ˜"""
    x_categorical = [item['x_categorical'] for item in batch]
    x_numerical = [item['x_numerical'] for item in batch]
    seqs = [item['seq'] for item in batch]
    
    if 'id' not in batch[0]:
        raise ValueError("âŒ ì˜ˆì¸¡ ì‹œì—ëŠ” IDê°€ ë°˜ë“œì‹œ í•„ìš”í•©ë‹ˆë‹¤!")
    
    ids = [item['id'] for item in batch]
    
    # ìŠ¤íƒìœ¼ë¡œ ë³€í™˜
    x_categorical = torch.stack(x_categorical)
    x_numerical = torch.stack(x_numerical)
    
    # ì‹œí€€ìŠ¤ íŒ¨ë”©
    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)
    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)
    seq_lengths = torch.clamp(seq_lengths, min=1)
    
    return {
        'x_categorical': x_categorical,
        'x_numerical': x_numerical,
        'seqs': seqs_padded,
        'seq_lengths': seq_lengths,
        'ids': ids
    }


def safe_load_parquet(file_path: str) -> pd.DataFrame:
    """ì•ˆì „í•œ parquet ë¡œë“œ í•¨ìˆ˜"""
    logger.info(f"ğŸ“Š ë°ì´í„° ë¡œë“œ: {file_path}")
    try:
        return pd.read_parquet(file_path, engine="pyarrow")
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def load_train_data_merlin(config: Dict) -> Tuple[pd.DataFrame, List[str], str, str]:
    """Merlin ê¸°ë°˜ í›ˆë ¨ ë°ì´í„° ë¡œë“œ"""
    logger.info("ğŸ“Š Merlin ê¸°ë°˜ í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    train = safe_load_parquet(config['PATHS']['TRAIN_DATA'])
    logger.info(f"âœ… í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {train.shape}")
    
    # í”¼ì²˜ ì •ë³´
    target_col = "clicked"
    seq_col = "seq"
    
    FEATURE_EXCLUDE = {target_col, seq_col, "ID"}
    feature_cols = [c for c in train.columns if c not in FEATURE_EXCLUDE]
    
    # í›ˆë ¨ ë°ì´í„°ì—ì„œ ID ì»¬ëŸ¼ ì œê±°
    if 'ID' in train.columns:
        train = train.drop(columns=['ID'])
        logger.info("âœ… í›ˆë ¨ ë°ì´í„°ì—ì„œ ID ì»¬ëŸ¼ ì œê±° ì™„ë£Œ")
    
    logger.info(f"ğŸ“Š í”¼ì²˜ ì •ë³´ - ì „ì²´: {len(feature_cols)}, ì‹œí€€ìŠ¤: {seq_col}, íƒ€ê²Ÿ: {target_col}")
    
    return train, feature_cols, seq_col, target_col


def load_test_data_merlin(config: Dict) -> pd.DataFrame:
    """Merlin ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
    logger.info("ğŸ“Š Merlin ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    test = safe_load_parquet(config['PATHS']['TEST_DATA'])
    
    if 'ID' not in test.columns:
        raise ValueError("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— 'ID' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {test.shape[0]}ê°œ í–‰")
    
    return test


# ê¸°ì¡´ í•¨ìˆ˜ë“¤ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼
def load_train_data(config):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    return load_train_data_merlin(config)


def load_test_data(config):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    return load_test_data_merlin(config)


# ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
FeatureProcessor = MerlinFeatureProcessor
ClickDataset = MerlinClickDataset
