"""
í‰ê°€ ë©”íŠ¸ë¦­ êµ¬í˜„
- AP (Average Precision, 50%): ì˜ˆì¸¡ í™•ë¥ ì— ëŒ€í•´ ê³„ì‚°ëœ í‰ê·  ì •ë°€ë„ ì ìˆ˜
- WLL (Weighted LogLoss, 50%): 'clicked'ì˜ 0ê³¼ 1ì˜ í´ë˜ìŠ¤ ê¸°ì—¬ë¥¼ 50:50ë¡œ ë§ì¶˜ ê°€ì¤‘ LogLoss
- Score = 0.5*AP + 0.5*(1/1+WLL)
"""

import numpy as np
import pandas as pd
from sklearn.metrics import average_precision_score, log_loss
import torch
import torch.nn.functional as F


def calculate_ap(y_true, y_pred):
    """
    Average Precision ê³„ì‚°
    
    Args:
        y_true: ì‹¤ì œ ë ˆì´ë¸” (0 ë˜ëŠ” 1)
        y_pred: ì˜ˆì¸¡ í™•ë¥  (0~1)
    
    Returns:
        float: Average Precision ì ìˆ˜
    """
    if len(np.unique(y_true)) < 2:
        # í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš°
        return 0.0
    
    return average_precision_score(y_true, y_pred)


def calculate_weighted_logloss(y_true, y_pred):
    """
    Weighted LogLoss ê³„ì‚° (50:50 ê°€ì¤‘ì¹˜)
    
    Args:
        y_true: ì‹¤ì œ ë ˆì´ë¸” (0 ë˜ëŠ” 1)
        y_pred: ì˜ˆì¸¡ í™•ë¥  (0~1)
    
    Returns:
        float: Weighted LogLoss ì ìˆ˜
    """
    # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
    class_counts = np.bincount(y_true.astype(int))
    
    if len(class_counts) < 2:
        # í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš°
        return float('inf')
    
    # í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚° (50:50ë¡œ ë§ì¶”ê¸° ìœ„í•´)
    total_samples = len(y_true)
    class_0_weight = total_samples / (2 * class_counts[0]) if class_counts[0] > 0 else 0
    class_1_weight = total_samples / (2 * class_counts[1]) if class_counts[1] > 0 else 0
    
    # ê°€ì¤‘ì¹˜ ì ìš©
    sample_weights = np.where(y_true == 0, class_0_weight, class_1_weight)
    
    # LogLoss ê³„ì‚°
    try:
        loss = log_loss(y_true, y_pred, sample_weight=sample_weights)
        return loss
    except ValueError:
        return float('inf')


def calculate_score(y_true, y_pred):
    """
    ìµœì¢… Score ê³„ì‚°: Score = 0.5*AP + 0.5*(1/1+WLL)
    
    Args:
        y_true: ì‹¤ì œ ë ˆì´ë¸” (0 ë˜ëŠ” 1)
        y_pred: ì˜ˆì¸¡ í™•ë¥  (0~1)
    
    Returns:
        dict: AP, WLL, Scoreë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    # AP ê³„ì‚°
    ap = calculate_ap(y_true, y_pred)
    
    # WLL ê³„ì‚°
    wll = calculate_weighted_logloss(y_true, y_pred)
    
    # Score ê³„ì‚°
    if wll == float('inf'):
        score = ap * 0.5  # WLLì´ ë¬´í•œëŒ€ì¸ ê²½ìš° APë§Œ ì‚¬ìš©
    else:
        score = 0.5 * ap + 0.5 * (1 / (1 + wll))
    
    return {
        'ap': ap,
        'wll': wll,
        'score': score
    }


def evaluate_model(model, data_loader, device="cuda"):
    """
    ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
    
    Args:
        model: í‰ê°€í•  ëª¨ë¸
        data_loader: í‰ê°€ ë°ì´í„° ë¡œë”
        device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
    
    Returns:
        dict: í‰ê°€ ê²°ê³¼ (loss, ap, wll, score)
    """
    model.eval()
    all_predictions = []
    all_targets = []
    total_loss = 0.0
    
    criterion = torch.nn.BCEWithLogitsLoss()
    
    with torch.no_grad():
        for xs, seqs, seq_lens, ys in data_loader:
            xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)
            
            # ì˜ˆì¸¡
            logits = model(xs, seqs, seq_lens)
            probs = torch.sigmoid(logits)
            
            # Loss ê³„ì‚°
            loss = criterion(logits, ys)
            total_loss += loss.item() * ys.size(0)
            
            # ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
            all_predictions.extend(probs.cpu().numpy().flatten())
            all_targets.extend(ys.cpu().numpy().flatten())
    
    # í‰ê·  Loss ê³„ì‚°
    avg_loss = total_loss / len(data_loader.dataset)
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = calculate_score(np.array(all_targets), np.array(all_predictions))
    metrics['loss'] = avg_loss
    
    return metrics


def print_metrics(metrics, prefix=""):
    """
    ë©”íŠ¸ë¦­ ê²°ê³¼ ì¶œë ¥
    
    Args:
        metrics: evaluate_modelì—ì„œ ë°˜í™˜ëœ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
        prefix: ì¶œë ¥ ì ‘ë‘ì‚¬
    """
    print(f"{prefix}Loss: {metrics['loss']:.6f}")
    print(f"{prefix}AP: {metrics['ap']:.6f}")
    print(f"{prefix}WLL: {metrics['wll']:.6f}")
    print(f"{prefix}Score: {metrics['score']:.6f}")


def save_training_logs(logs, filepath):
    """
    í›ˆë ¨ ë¡œê·¸ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        logs: í›ˆë ¨ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ (ê° ìš”ì†ŒëŠ” ë”•ì…”ë„ˆë¦¬)
        filepath: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    df = pd.DataFrame(logs)
    df.to_csv(filepath, index=False)
    print(f"ğŸ“Š í›ˆë ¨ ë¡œê·¸ ì €ì¥: {filepath}")
    print(f"   â€¢ ì´ {len(logs)}ê°œ ì—í¬í¬ ê¸°ë¡")
    print(f"   â€¢ ìµœê³  Score: {df['val_score'].max():.6f} (Epoch {df['val_score'].idxmax() + 1})")


def get_best_checkpoint_info(logs):
    """
    ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ë°˜í™˜
    
    Args:
        logs: í›ˆë ¨ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        dict: ìµœê³  ì„±ëŠ¥ ì •ë³´
    """
    if not logs:
        return None
    
    df = pd.DataFrame(logs)
    best_idx = df['val_score'].idxmax()
    best_epoch = best_idx + 1
    
    return {
        'epoch': best_epoch,
        'val_score': df.loc[best_idx, 'val_score'],
        'val_ap': df.loc[best_idx, 'val_ap'],
        'val_wll': df.loc[best_idx, 'val_wll'],
        'val_loss': df.loc[best_idx, 'val_loss'],
        'train_loss': df.loc[best_idx, 'train_loss']
    }
