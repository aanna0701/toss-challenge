#!/usr/bin/env python3
"""
í›ˆë ¨ í›„ ìë™ìœ¼ë¡œ ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë‚ ì§œë³„ë¡œ ì €ì¥í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ìŠ¤í¬ë¦½íŠ¸
"""

import os
import gc
import psutil
import traceback
import logging
import argparse
from datetime import datetime
import yaml

def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='í›ˆë ¨ ë° ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰')
    parser.add_argument('--config', type=str, required=True,
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (í•„ìˆ˜)')
    return parser.parse_args()

def load_config(config_path):
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"ğŸ“‹ ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
    return config

# ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹± ë° ì„¤ì • ë¡œë“œ
args = parse_args()
CFG = load_config(args.config)

from utils import seed_everything, get_device
from data_loader import load_and_preprocess_data
from model import *
from train import train_model, save_model
from predict import predict_test_data

DEVICE = get_device()

def create_results_directory():
    """ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
    # í›ˆë ¨ ë°ì´í„° ê²½ë¡œì—ì„œ fold ì •ë³´ ì¶”ì¶œ
    train_data_path = CFG['PATHS']['TRAIN_DATA']
    
    # train_fold1.parquet -> fold1, train_fold2.parquet -> fold2
    if 'train_fold' in train_data_path:
        fold_match = os.path.basename(train_data_path).replace('train_fold', '').replace('.parquet', '')
        folder_name = f"fold{fold_match}"
    else:
        folder_name = "full_data"
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = f"{folder_name}_{timestamp}"
    
    # ê¸°ì¡´ results ë””ë ‰í† ë¦¬ê°€ ìˆìœ¼ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
    if os.path.exists(results_dir):
        import shutil
        shutil.rmtree(results_dir)
        print(f"ğŸ—‘ï¸  ê¸°ì¡´ ê²°ê³¼ ë””ë ‰í† ë¦¬ ì‚­ì œ: {results_dir}")
    
    os.makedirs(results_dir, exist_ok=True)
    print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}")
    return results_dir

def setup_error_logging(results_dir):
    """ì—ëŸ¬ ë¡œê¹… ì„¤ì •"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    error_log_path = os.path.join(results_dir, f"error_log_{timestamp}.log")
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.ERROR,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(error_log_path, encoding='utf-8'),
            logging.StreamHandler()  # ì½˜ì†”ì—ë„ ì¶œë ¥
        ]
    )
    
    print(f"ğŸ“‹ ì—ëŸ¬ ë¡œê·¸ ì„¤ì • ì™„ë£Œ: {error_log_path}")
    return error_log_path

def log_error(error, error_log_path, step_info=None):
    """ì—ëŸ¬ë¥¼ íŒŒì¼ì— ë¡œê¹…"""
    error_info = {
        'timestamp': datetime.now().isoformat(),
        'error_type': type(error).__name__,
        'error_message': str(error),
        'step_info': step_info,
        'memory_usage': f"{get_memory_usage():.1f} MB",
        'traceback': traceback.format_exc()
    }
    
    # ìƒì„¸ ì—ëŸ¬ ì •ë³´ë¥¼ íŒŒì¼ì— ì €ì¥
    with open(error_log_path, 'a', encoding='utf-8') as f:
        f.write(f"\n{'='*80}\n")
        f.write(f"ERROR OCCURRED\n")
        f.write(f"{'='*80}\n")
        f.write(f"Timestamp: {error_info['timestamp']}\n")
        f.write(f"Error Type: {error_info['error_type']}\n")
        f.write(f"Error Message: {error_info['error_message']}\n")
        f.write(f"Memory Usage: {error_info['memory_usage']}\n")
        if step_info:
            f.write(f"Step Info: {step_info}\n")
        f.write(f"\nTraceback:\n{error_info['traceback']}\n")
        f.write(f"{'='*80}\n")
    
    # ë¡œê¹… ì‹œìŠ¤í…œì—ë„ ê¸°ë¡
    logging.error(f"Error occurred: {error_info['error_type']} - {error_info['error_message']}")
    
    print(f"ğŸ“‹ ì—ëŸ¬ê°€ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {error_log_path}")

def save_error_summary(results_dir, error_log_path, error_count=1):
    """ì—ëŸ¬ ìš”ì•½ ì •ë³´ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    summary_path = os.path.join(results_dir, f"error_summary_{timestamp}.json")
    
    summary = {
        'timestamp': timestamp,
        'total_errors': error_count,
        'error_log_file': os.path.basename(error_log_path),
        'results_directory': results_dir,
        'system_info': {
            'memory_usage': f"{get_memory_usage():.1f} MB",
            'python_version': f"{os.sys.version}",
            'platform': f"{os.sys.platform}"
        }
    }
    
    import json
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ ì—ëŸ¬ ìš”ì•½ ì €ì¥: {summary_path}")
    return summary_path


def get_memory_usage():
    """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    memory_mb = memory_info.rss / 1024 / 1024
    return memory_mb

def print_model_summary(model, log_file_path=None, input_size=None):
    """torchinfoë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ìƒì„¸ êµ¬ì¡°ë¥¼ ì¶œë ¥í•˜ê³  ë¡œê·¸ íŒŒì¼ì— ì €ì¥"""
    try:
        from torchinfo import summary
        
        # ì…ë ¥ í¬ê¸° ì„¤ì • (ê¸°ë³¸ê°’)
        if input_size is None:
            # TabularTransformer ëª¨ë¸ì˜ ê²½ìš° ëŒ€ëµì ì¸ ì…ë ¥ í¬ê¸° ì„¤ì •
            input_size = [
                (1, 10),  # x_categorical: (batch_size, num_categorical_features)
                (1, 20),  # x_numerical: (batch_size, num_numerical_features)  
                (1, 50),  # x_seq: (batch_size, seq_length)
                (1,),     # seq_lengths: (batch_size,)
                (1, 31)   # nan_mask: (batch_size, total_features)
            ]
        
        # torchinfoë¡œ ëª¨ë¸ ìš”ì•½ ìƒì„±
        model_summary = summary(
            model,
            input_size=input_size,
            col_names=["input_size", "output_size", "num_params", "trainable"],
            verbose=0
        )
        
        # ë¡œê·¸ íŒŒì¼ì— ì €ì¥
        if log_file_path:
            with open(log_file_path, 'w', encoding='utf-8') as f:
                f.write(f"ëª¨ë¸ êµ¬ì¡° Summary - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 80 + "\n")
                f.write(str(model_summary))
                f.write("\n" + "=" * 80 + "\n")
            print(f"ğŸ“‹ ëª¨ë¸ êµ¬ì¡°ê°€ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {log_file_path}")
            
    except ImportError:
        print("âš ï¸  torchinfoê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install torchinfoë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        print("ê¸°ë³¸ summaryë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
        
        # ê¸°ë³¸ summary (fallback)
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        summary_text = f"""
ëª¨ë¸ êµ¬ì¡° Summary - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'=' * 80}
ëª¨ë¸ íƒ€ì…: {type(model).__name__}
ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}
í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {trainable_params:,}
í•™ìŠµ ë¶ˆê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {total_params - trainable_params:,}
{'=' * 80}
        """
        
        print(summary_text)
        
        if log_file_path:
            with open(log_file_path, 'w', encoding='utf-8') as f:
                f.write(summary_text)
            print(f"ğŸ“‹ ëª¨ë¸ êµ¬ì¡°ê°€ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {log_file_path}")
            
    except Exception as e:
        print(f"âš ï¸  ëª¨ë¸ summary ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ê¸°ë³¸ summaryë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
        
        # ê¸°ë³¸ summary (fallback)
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        summary_text = f"""
ëª¨ë¸ êµ¬ì¡° Summary - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'=' * 80}
ëª¨ë¸ íƒ€ì…: {type(model).__name__}
ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}
í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {trainable_params:,}
í•™ìŠµ ë¶ˆê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°: {total_params - trainable_params:,}
{'=' * 80}
        """
        
        print(summary_text)
        
        if log_file_path:
            with open(log_file_path, 'w', encoding='utf-8') as f:
                f.write(summary_text)
            print(f"ğŸ“‹ ëª¨ë¸ êµ¬ì¡°ê°€ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {log_file_path}")

def cleanup_memory():
    """ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜"""
    print(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘ (í˜„ì¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB)")
    
    # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    collected = gc.collect()
    print(f"   â€¢ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜: {collected}ê°œ ê°ì²´ ì •ë¦¬")
    
    # PyTorch ìºì‹œ ì •ë¦¬
    import torch
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print(f"   â€¢ CUDA ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
    
    print(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (í˜„ì¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB)")

def cleanup_train_data(train_data, test_data=None):
    """í›ˆë ¨ ë°ì´í„° ë° ê´€ë ¨ ë³€ìˆ˜ ë©”ëª¨ë¦¬ì—ì„œ ì œê±°"""
    print(f"ğŸ—‘ï¸  í›ˆë ¨ ë°ì´í„° ë©”ëª¨ë¦¬ì—ì„œ ì œê±° ì‹œì‘ (í˜„ì¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB)")
    
    # í›ˆë ¨ ë°ì´í„° ì‚­ì œ
    del train_data
    print(f"   â€¢ train_data ë³€ìˆ˜ ì‚­ì œ")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì˜ˆì¸¡ì— í•„ìš”í•˜ë¯€ë¡œ ìœ ì§€
    if test_data is not None:
        print(f"   â€¢ test_data ìœ ì§€ (ì˜ˆì¸¡ì— í•„ìš”)")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    cleanup_memory()

def cleanup_temp_files(temp_model_path):
    """ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ"""
    if os.path.exists(temp_model_path):
        os.remove(temp_model_path)
        print(f"ğŸ—‘ï¸  ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ: {temp_model_path}")
    else:
        print(f"âš ï¸  ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {temp_model_path}")


def save_results_with_metadata(results_dir, submission_df, model_info, model_path=None):
    """ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    submission_path = os.path.join(results_dir, f"submission_{timestamp}.csv")
    submission_df.to_csv(submission_path, index=False)
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {submission_path}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'timestamp': timestamp,
        'model_info': model_info,
        'config': CFG,
        'submission_shape': submission_df.shape,
        'model_used': "Best Checkpoint" if model_path and "best.pth" in model_path else "Temp Model",
        'model_path': model_path,
        'submission_stats': {
            'mean_prediction': float(submission_df['clicked'].mean()),
            'min_prediction': float(submission_df['clicked'].min()),
            'max_prediction': float(submission_df['clicked'].max()),
            'std_prediction': float(submission_df['clicked'].std())
        }
    }
    
    metadata_path = os.path.join(results_dir, f"metadata_{timestamp}.json")
    import json
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
    print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
    
    return submission_path, metadata_path


def print_progress(step, total_steps, description):
    """ì§„í–‰ìƒí™© í”„ë¦°íŠ¸ í•¨ìˆ˜"""
    progress = f"[{step}/{total_steps}]"
    print(f"\n{'='*20} {progress} {description} {'='*20}")
    print(f"â° ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def print_step_summary(step_name, details):
    """ë‹¨ê³„ë³„ ìš”ì•½ ì •ë³´ í”„ë¦°íŠ¸"""
    print(f"\nğŸ“‹ {step_name} ì™„ë£Œ:")
    for key, value in details.items():
        print(f"   â€¢ {key}: {value}")

def safe_execute_step(step_func, step_name, error_log_path, *args, **kwargs):
    """ì•ˆì „í•˜ê²Œ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ê³  ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê¹…"""
    try:
        return step_func(*args, **kwargs)
    except Exception as e:
        step_info = f"ë‹¨ê³„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {step_name}"
        log_error(e, error_log_path, step_info)
        raise


def main():
    """ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    total_steps = 11
    print("ğŸš€ í›ˆë ¨ â†’ ì˜ˆì¸¡ â†’ ê²°ê³¼ ì €ì¥ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    print("=" * 80)
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‹ ì„¤ì • íŒŒì¼: {args.config}")
    print(f"ğŸ”§ ì´ ë‹¨ê³„: {total_steps}ë‹¨ê³„")
    
    # 1. ì´ˆê¸°í™”
    print_progress(1, total_steps, "ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
    # ì‹œë“œ ê³ ì •
    seed_everything(CFG['SEED'])
    print(f"Device: {DEVICE}")
    
    # ì´ˆê¸°í™” ìš”ì•½ ì •ë³´ ì„¤ì •
    data_loading_info = f"ë°ì´í„°: {CFG['PATHS']['TRAIN_DATA']}"
    
    print_step_summary("ì´ˆê¸°í™”", {
        "Device": DEVICE,
        "Epochs": CFG['EPOCHS'],
        "Batch Size": CFG['BATCH_SIZE'],
        "Learning Rate": CFG['LEARNING_RATE'],
        "Weight Decay": CFG['WEIGHT_DECAY'],
        "Data Loading": data_loading_info
    })
    
    # 2. ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    print_progress(2, total_steps, "ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±")
    results_dir = create_results_directory()
    
    # ì—ëŸ¬ ë¡œê¹… ì„¤ì •
    error_log_path = setup_error_logging(results_dir)
    
    print_step_summary("ë””ë ‰í† ë¦¬ ìƒì„±", {
        "Results Dir": results_dir,
        "Error Log": os.path.basename(error_log_path)
    })
    
    # 3. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    temp_model_path = f"temp_model_{timestamp}.pth"
    print(f"ğŸ“ ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ê²½ë¡œ: {temp_model_path}")
    
    try:
        # 4. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        print_progress(3, total_steps, "ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
        print(f"ğŸ’¾ ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        # ë°ì´í„° ë¡œë“œ
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ì‹œì‘...")
        print(f"   â€¢ í›ˆë ¨ ë°ì´í„°: {CFG['PATHS']['TRAIN_DATA']}")
        print(f"   â€¢ í…ŒìŠ¤íŠ¸ ë°ì´í„°: ./test.parquet")
        
        train_data, test_data, feature_cols, seq_col, target_col = load_and_preprocess_data(CFG)
        print(f"ğŸ’¾ ë°ì´í„° ë¡œë“œ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        # ë°ì´í„° ë¡œë”© ì •ë³´ ì„¤ì •
        data_loading_info = f"ë°ì´í„°: {CFG['PATHS']['TRAIN_DATA']}"
        
        print_step_summary("ë°ì´í„° ë¡œë“œ", {
            "Train Shape": train_data.shape,
            "Test Shape": test_data.shape,
            "Features": len(feature_cols),
            "Sequence Column": seq_col,
            "Target Column": target_col,
            "Test ID Column": "ID" in test_data.columns,
            "Data Loading": data_loading_info,
            "Memory Usage": f"{get_memory_usage():.1f} MB"
        })
        
        # 5. ëª¨ë¸ í›ˆë ¨
        model, feature_processor = train_model(
            train_df=train_data,
            feature_cols=feature_cols,
            seq_col=seq_col,
            target_col=target_col,
            CFG=CFG,
            device=DEVICE,
            results_dir=results_dir
        )
        print_step_summary("ëª¨ë¸ í›ˆë ¨", {
            "Model Type": "TabularTransformer",
            "Epochs Completed": CFG['EPOCHS'],
            "Device Used": DEVICE,
            "Checkpoint Interval": "Every 5 epochs"
        })
        
        # 6. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì €ì¥
        print_progress(5, total_steps, "ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì €ì¥")
        save_model(model, temp_model_path, feature_processor)
        
        # Best checkpoint ê²½ë¡œ ì„¤ì •
        best_model_path = os.path.join(results_dir, "best.pth")
        print(f"ğŸ† Best checkpoint ê²½ë¡œ: {best_model_path}")
        
        print_step_summary("ì›¨ì´íŠ¸ ì €ì¥", {
            "Temp Model": temp_model_path,
            "Best Model": best_model_path
        })
        
        # 6.5. í›ˆë ¨ ë°ì´í„° ë©”ëª¨ë¦¬ì—ì„œ ì œê±°
        print_progress(6, total_steps, "í›ˆë ¨ ë°ì´í„° ë©”ëª¨ë¦¬ ì •ë¦¬")
        print(f"ğŸ’¾ í›ˆë ¨ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        # í›ˆë ¨ì— í•„ìš”í•œ ì •ë³´ë§Œ ì €ì¥
        train_shape = train_data.shape
        model_info_data = {
            'train_shape': train_shape,
            'test_shape': test_data.shape,
            'num_features': len(feature_cols)
        }
        
        # í›ˆë ¨ ë°ì´í„° ë©”ëª¨ë¦¬ì—ì„œ ì œê±°
        cleanup_train_data(train_data, test_data)
        print_step_summary("ë©”ëª¨ë¦¬ ì •ë¦¬", {
            "Train Data": "ë©”ëª¨ë¦¬ì—ì„œ ì œê±°ë¨",
            "Test Data": "ìœ ì§€ë¨ (ì˜ˆì¸¡ì— í•„ìš”)",
            "Memory Usage": f"{get_memory_usage():.1f} MB"
        })
        
        # 7. ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘
        print_progress(7, total_steps, "ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘")
        model_info = {
            'model_type': 'tabular_transformer',
            'hidden_dim': CFG['MODEL']['TRANSFORMER']['HIDDEN_DIM'],
            'n_heads': CFG['MODEL']['TRANSFORMER']['N_HEADS'],
            'n_layers': CFG['MODEL']['TRANSFORMER']['N_LAYERS'],
            'lstm_hidden': CFG['MODEL']['TRANSFORMER']['HIDDEN_DIM'],  # same as hidden_dim
            'epochs': CFG['EPOCHS'],
            'learning_rate': CFG['LEARNING_RATE'],
            'weight_decay': CFG['WEIGHT_DECAY'],
            'batch_size': CFG['BATCH_SIZE'],
            'train_shape': model_info_data['train_shape'],
            'test_shape': model_info_data['test_shape'],
            'num_features': model_info_data['num_features'],
            'early_stopping': CFG['EARLY_STOPPING']['ENABLED'],
            'monitor_metric': CFG['EARLY_STOPPING']['MONITOR'],
            'patience': CFG['EARLY_STOPPING']['PATIENCE']
        }
        print_step_summary("ì •ë³´ ìˆ˜ì§‘", {
            "Model Parameters": len(model_info),
            "Training Data Shape": model_info_data['train_shape'],
            "Test Data Shape": model_info_data['test_shape']
        })
        
        # 8. ì˜ˆì¸¡ ì‹¤í–‰
        print_progress(8, total_steps, "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡")
        print(f"ğŸ”® ì˜ˆì¸¡ ì„¤ì •:")
        print(f"   â€¢ Test Data Shape: {test_data.shape}")
        print(f"   â€¢ Features: {len(feature_cols)}")
        print(f"   â€¢ Batch Size: {CFG['BATCH_SIZE']}")
        print(f"ğŸ’¾ ì˜ˆì¸¡ ì „ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        # Best checkpointê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì„ì‹œ ëª¨ë¸ ì‚¬ìš©
        model_path_for_prediction = best_model_path if os.path.exists(best_model_path) else temp_model_path
        print(f"ğŸ”® ì˜ˆì¸¡ì— ì‚¬ìš©í•  ëª¨ë¸: {model_path_for_prediction}")
        
        submission_df = predict_test_data(
            test_data=test_data,
            feature_cols=feature_cols,
            seq_col=seq_col,
            CFG=CFG,
            model_path=model_path_for_prediction,
            device=DEVICE,
            feature_processor=feature_processor
        )
        print(f"ğŸ’¾ ì˜ˆì¸¡ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        print_step_summary("ì˜ˆì¸¡ ì™„ë£Œ", {
            "Submission Shape": submission_df.shape,
            "Mean Prediction": f"{submission_df['clicked'].mean():.4f}",
            "Min Prediction": f"{submission_df['clicked'].min():.4f}",
            "Max Prediction": f"{submission_df['clicked'].max():.4f}",
            "Model Used": "Best Checkpoint" if "best.pth" in model_path_for_prediction else "Temp Model",
            "Memory Usage": f"{get_memory_usage():.1f} MB"
        })
        
        # 9. ê²°ê³¼ ì €ì¥
        print_progress(9, total_steps, "ê²°ê³¼ ë° ë©”íƒ€ë°ì´í„° ì €ì¥")
        submission_path, metadata_path = save_results_with_metadata(
            results_dir, submission_df, model_info, model_path_for_prediction
        )
        print_step_summary("ê²°ê³¼ ì €ì¥", {
            "Submission File": submission_path,
            "Metadata File": metadata_path,
            "Results Directory": results_dir
        })
        
        # 10. ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ìš”ì•½
        print_progress(10, total_steps, "ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ìš”ì•½")
        print(f"ğŸ’¾ ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        print("\nâœ… ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
        print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼: {submission_path}")
        print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°: {metadata_path}")
        print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ğŸ” ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}")
        print(f"ğŸ’¾ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        # ì—ëŸ¬ ë¡œê¹…
        step_info = f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {type(e).__name__}"
        log_error(e, error_log_path, step_info)
        
        # ì—ëŸ¬ ìš”ì•½ ì €ì¥
        save_error_summary(results_dir, error_log_path)
        
        print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        print(f"\nğŸ“‹ ì—ëŸ¬ ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜: {error_log_path}")
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
        raise
    
    finally:
        # 11. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ
        print_progress(11, total_steps, "ì •ë¦¬ ì‘ì—…")
        cleanup_temp_files(temp_model_path)
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)
    print(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
