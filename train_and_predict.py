#!/usr/bin/env python3
"""
í›ˆë ¨ í›„ ìë™ìœ¼ë¡œ ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë‚ ì§œë³„ë¡œ ì €ì¥í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ìŠ¤í¬ë¦½íŠ¸
"""

import os
from datetime import datetime
import yaml

# config_debug.yaml ë¡œë“œ
with open('config.yaml', 'r', encoding='utf-8') as f:
    CFG = yaml.safe_load(f)

from main import device
from utils import seed_everything
from data_loader import load_and_preprocess_data
from model import *
from train import train_model, save_model
from predict import predict_test_data


def create_results_directory():
    """ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
    # {datetime}ì„ ì‹¤ì œ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì¹˜í™˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = CFG['PATHS']['RESULTS_DIR'].replace('{datetime}', timestamp)
    os.makedirs(results_dir, exist_ok=True)
    print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}")
    return results_dir


def cleanup_temp_files(temp_model_path):
    """ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ"""
    if os.path.exists(temp_model_path):
        os.remove(temp_model_path)
        print(f"ğŸ—‘ï¸  ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ: {temp_model_path}")
    else:
        print(f"âš ï¸  ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {temp_model_path}")


def save_results_with_metadata(results_dir, submission_df, model_info):
    """ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    submission_path = os.path.join(results_dir, f"submission_{timestamp}.csv")
    submission_df.to_csv(submission_path, index=False)
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {submission_path}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'timestamp': timestamp,
        'model_info': model_info,
        'config': CFG,
        'submission_shape': submission_df.shape,
        'submission_stats': {
            'mean_prediction': float(submission_df['clicked'].mean()),
            'min_prediction': float(submission_df['clicked'].min()),
            'max_prediction': float(submission_df['clicked'].max()),
            'std_prediction': float(submission_df['clicked'].std())
        }
    }
    
    metadata_path = os.path.join(results_dir, f"metadata_{timestamp}.json")
    import json
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
    print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
    
    return submission_path, metadata_path


def print_progress(step, total_steps, description):
    """ì§„í–‰ìƒí™© í”„ë¦°íŠ¸ í•¨ìˆ˜"""
    progress = f"[{step}/{total_steps}]"
    print(f"\n{'='*20} {progress} {description} {'='*20}")
    print(f"â° ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def print_step_summary(step_name, details):
    """ë‹¨ê³„ë³„ ìš”ì•½ ì •ë³´ í”„ë¦°íŠ¸"""
    print(f"\nğŸ“‹ {step_name} ì™„ë£Œ:")
    for key, value in details.items():
        print(f"   â€¢ {key}: {value}")


def main():
    """ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    total_steps = 10
    print("ğŸš€ í›ˆë ¨ â†’ ì˜ˆì¸¡ â†’ ê²°ê³¼ ì €ì¥ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    print("=" * 80)
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”§ ì´ ë‹¨ê³„: {total_steps}ë‹¨ê³„")
    
    # 1. ì´ˆê¸°í™”
    print_progress(1, total_steps, "ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
    # ì‹œë“œ ê³ ì •
    seed_everything(CFG['SEED'])
    print(f"Device: {device}")
    print_step_summary("ì´ˆê¸°í™”", {
        "Device": device,
        "Epochs": CFG['EPOCHS'],
        "Batch Size": CFG['BATCH_SIZE'],
        "Learning Rate": CFG['LEARNING_RATE'],
        "Data Sampling": CFG['DATA']['USE_SAMPLING'],
        "Sample Size": CFG['DATA']['SAMPLE_SIZE']
    })
    
    # 2. ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    print_progress(2, total_steps, "ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±")
    results_dir = create_results_directory()
    print_step_summary("ë””ë ‰í† ë¦¬ ìƒì„±", {"Results Dir": results_dir})
    
    # 3. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    temp_model_path = CFG['PATHS']['TEMP_MODEL'].replace('{datetime}', timestamp)
    print(f"ğŸ“ ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ê²½ë¡œ: {temp_model_path}")
    
    try:
        # 4. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        print_progress(3, total_steps, "ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
        # í›ˆë ¨ ë°ì´í„°: config.yamlì˜ USE_SAMPLING ì„¤ì •ì— ë”°ë¼ ìƒ˜í”Œë§ ë˜ëŠ” ì „ì²´ ë¡œë“œ
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°: ë¬´ì¡°ê±´ ì „ì²´ ë°ì´í„° ë¡œë“œ (force_full_load=True)
        train_data, test_data, feature_cols, seq_col, target_col = load_and_preprocess_data()
        print_step_summary("ë°ì´í„° ë¡œë“œ", {
            "Train Shape": train_data.shape,
            "Test Shape": test_data.shape,
            "Features": len(feature_cols),
            "Sequence Column": seq_col,
            "Target Column": target_col,
            "Test ID Column": "ID" in test_data.columns,
            "Data Sampling": CFG['DATA']['USE_SAMPLING'],
            "Test Data": "ì „ì²´ ë¡œë“œ (ìƒ˜í”Œë§ ì—†ìŒ)"
        })
        
        # 5. ëª¨ë¸ í›ˆë ¨
        print_progress(4, total_steps, "ëª¨ë¸ í›ˆë ¨")
        print(f"ğŸ‹ï¸ ëª¨ë¸ ì„¤ì •:")
        print(f"   â€¢ Type: {CFG['MODEL']['TYPE']}")
        if CFG['MODEL']['TYPE'] == 'tabular_seq':
            print(f"   â€¢ LSTM Hidden: {CFG['MODEL']['LSTM_HIDDEN']}")
            print(f"   â€¢ Hidden Units: {CFG['MODEL']['HIDDEN_UNITS']}")
            print(f"   â€¢ Dropout: {CFG['MODEL']['DROPOUT']}")
        elif CFG['MODEL']['TYPE'] == 'tabular_transformer':
            print(f"   â€¢ Hidden Dim: {CFG['MODEL']['TRANSFORMER']['HIDDEN_DIM']}")
            print(f"   â€¢ N Heads: {CFG['MODEL']['TRANSFORMER']['N_HEADS']}")
            print(f"   â€¢ N Layers: {CFG['MODEL']['TRANSFORMER']['N_LAYERS']}")
            print(f"   â€¢ LSTM Hidden: {CFG['MODEL']['TRANSFORMER']['LSTM_HIDDEN']}")
        
        model = train_model(
            train_df=train_data,
            feature_cols=feature_cols,
            seq_col=seq_col,
            target_col=target_col,
            device=device
        )
        print_step_summary("ëª¨ë¸ í›ˆë ¨", {
            "Model Type": CFG['MODEL']['TYPE'],
            "Epochs Completed": CFG['EPOCHS'],
            "Device Used": device
        })
        
        # 6. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì €ì¥
        print_progress(5, total_steps, "ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì €ì¥")
        save_model(model, temp_model_path)
        print_step_summary("ì›¨ì´íŠ¸ ì €ì¥", {"File Path": temp_model_path})
        
        # 7. ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘
        print_progress(6, total_steps, "ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘")
        model_info = {
            'model_type': CFG['MODEL']['TYPE'],
            'lstm_hidden': CFG['MODEL']['LSTM_HIDDEN'],
            'hidden_units': CFG['MODEL']['HIDDEN_UNITS'],
            'dropout': CFG['MODEL']['DROPOUT'],
            'epochs': CFG['EPOCHS'],
            'learning_rate': CFG['LEARNING_RATE'],
            'batch_size': CFG['BATCH_SIZE'],
            'train_shape': train_data.shape,
            'test_shape': test_data.shape,
            'num_features': len(feature_cols),
            'early_stopping': CFG['EARLY_STOPPING']['ENABLED'],
            'monitor_metric': CFG['EARLY_STOPPING']['MONITOR'],
            'patience': CFG['EARLY_STOPPING']['PATIENCE']
        }
        print_step_summary("ì •ë³´ ìˆ˜ì§‘", {
            "Model Parameters": len(model_info),
            "Training Data Shape": train_data.shape,
            "Test Data Shape": test_data.shape
        })
        
        # 8. ì˜ˆì¸¡ ì‹¤í–‰
        print_progress(7, total_steps, "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡")
        print(f"ğŸ”® ì˜ˆì¸¡ ì„¤ì •:")
        print(f"   â€¢ Test Data Shape: {test_data.shape}")
        print(f"   â€¢ Features: {len(feature_cols)}")
        print(f"   â€¢ Batch Size: {CFG['BATCH_SIZE']}")
        
        submission_df = predict_test_data(
            test_data=test_data,
            feature_cols=feature_cols,
            seq_col=seq_col,
            model_path=temp_model_path,
            device=device
        )
        print_step_summary("ì˜ˆì¸¡ ì™„ë£Œ", {
            "Submission Shape": submission_df.shape,
            "Mean Prediction": f"{submission_df['clicked'].mean():.4f}",
            "Min Prediction": f"{submission_df['clicked'].min():.4f}",
            "Max Prediction": f"{submission_df['clicked'].max():.4f}"
        })
        
        # 9. ê²°ê³¼ ì €ì¥
        print_progress(8, total_steps, "ê²°ê³¼ ë° ë©”íƒ€ë°ì´í„° ì €ì¥")
        submission_path, metadata_path = save_results_with_metadata(
            results_dir, submission_df, model_info
        )
        print_step_summary("ê²°ê³¼ ì €ì¥", {
            "Submission File": submission_path,
            "Metadata File": metadata_path,
            "Results Directory": results_dir
        })
        
        # 10. ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ìš”ì•½
        print_progress(9, total_steps, "ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ìš”ì•½")
        print("\nâœ… ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
        print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼: {submission_path}")
        print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°: {metadata_path}")
        print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        raise
    
    finally:
        # 11. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ
        print_progress(10, total_steps, "ì •ë¦¬ ì‘ì—…")
        cleanup_temp_files(temp_model_path)
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)
    print(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
