#!/usr/bin/env python3
"""
í›ˆë ¨ í›„ ìë™ìœ¼ë¡œ ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë‚ ì§œë³„ë¡œ ì €ì¥í•˜ëŠ” ì›Œí¬í”Œë¡œìš° ìŠ¤í¬ë¦½íŠ¸
"""

import os
import gc
import psutil
import traceback
import logging
from datetime import datetime
import yaml

# config_debug.yaml ë¡œë“œ
with open('config.yaml', 'r', encoding='utf-8') as f:
    CFG = yaml.safe_load(f)

from main import device
from utils import seed_everything
from data_loader import load_and_preprocess_data
from model import *
from train import train_model, save_model
from predict import predict_test_data


def create_results_directory():
    """ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
    # {datetime}ì„ ì‹¤ì œ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì¹˜í™˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = CFG['PATHS']['RESULTS_DIR'].replace('{datetime}', timestamp)
    os.makedirs(results_dir, exist_ok=True)
    print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}")
    return results_dir

def setup_error_logging(results_dir):
    """ì—ëŸ¬ ë¡œê¹… ì„¤ì •"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    error_log_path = os.path.join(results_dir, f"error_log_{timestamp}.log")
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.ERROR,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(error_log_path, encoding='utf-8'),
            logging.StreamHandler()  # ì½˜ì†”ì—ë„ ì¶œë ¥
        ]
    )
    
    print(f"ğŸ“‹ ì—ëŸ¬ ë¡œê·¸ ì„¤ì • ì™„ë£Œ: {error_log_path}")
    return error_log_path

def log_error(error, error_log_path, step_info=None):
    """ì—ëŸ¬ë¥¼ íŒŒì¼ì— ë¡œê¹…"""
    error_info = {
        'timestamp': datetime.now().isoformat(),
        'error_type': type(error).__name__,
        'error_message': str(error),
        'step_info': step_info,
        'memory_usage': f"{get_memory_usage():.1f} MB",
        'traceback': traceback.format_exc()
    }
    
    # ìƒì„¸ ì—ëŸ¬ ì •ë³´ë¥¼ íŒŒì¼ì— ì €ì¥
    with open(error_log_path, 'a', encoding='utf-8') as f:
        f.write(f"\n{'='*80}\n")
        f.write(f"ERROR OCCURRED\n")
        f.write(f"{'='*80}\n")
        f.write(f"Timestamp: {error_info['timestamp']}\n")
        f.write(f"Error Type: {error_info['error_type']}\n")
        f.write(f"Error Message: {error_info['error_message']}\n")
        f.write(f"Memory Usage: {error_info['memory_usage']}\n")
        if step_info:
            f.write(f"Step Info: {step_info}\n")
        f.write(f"\nTraceback:\n{error_info['traceback']}\n")
        f.write(f"{'='*80}\n")
    
    # ë¡œê¹… ì‹œìŠ¤í…œì—ë„ ê¸°ë¡
    logging.error(f"Error occurred: {error_info['error_type']} - {error_info['error_message']}")
    
    print(f"ğŸ“‹ ì—ëŸ¬ê°€ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {error_log_path}")

def save_error_summary(results_dir, error_log_path, error_count=1):
    """ì—ëŸ¬ ìš”ì•½ ì •ë³´ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    summary_path = os.path.join(results_dir, f"error_summary_{timestamp}.json")
    
    summary = {
        'timestamp': timestamp,
        'total_errors': error_count,
        'error_log_file': os.path.basename(error_log_path),
        'results_directory': results_dir,
        'system_info': {
            'memory_usage': f"{get_memory_usage():.1f} MB",
            'python_version': f"{os.sys.version}",
            'platform': f"{os.sys.platform}"
        }
    }
    
    import json
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“‹ ì—ëŸ¬ ìš”ì•½ ì €ì¥: {summary_path}")
    return summary_path


def get_memory_usage():
    """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    memory_mb = memory_info.rss / 1024 / 1024
    return memory_mb

def cleanup_memory():
    """ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜"""
    print(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘ (í˜„ì¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB)")
    
    # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    collected = gc.collect()
    print(f"   â€¢ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜: {collected}ê°œ ê°ì²´ ì •ë¦¬")
    
    # PyTorch ìºì‹œ ì •ë¦¬
    import torch
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print(f"   â€¢ CUDA ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
    
    print(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ (í˜„ì¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB)")

def cleanup_train_data(train_data, test_data=None):
    """í›ˆë ¨ ë°ì´í„° ë° ê´€ë ¨ ë³€ìˆ˜ ë©”ëª¨ë¦¬ì—ì„œ ì œê±°"""
    print(f"ğŸ—‘ï¸  í›ˆë ¨ ë°ì´í„° ë©”ëª¨ë¦¬ì—ì„œ ì œê±° ì‹œì‘ (í˜„ì¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB)")
    
    # í›ˆë ¨ ë°ì´í„° ì‚­ì œ
    del train_data
    print(f"   â€¢ train_data ë³€ìˆ˜ ì‚­ì œ")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì˜ˆì¸¡ì— í•„ìš”í•˜ë¯€ë¡œ ìœ ì§€
    if test_data is not None:
        print(f"   â€¢ test_data ìœ ì§€ (ì˜ˆì¸¡ì— í•„ìš”)")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    cleanup_memory()

def cleanup_temp_files(temp_model_path):
    """ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ"""
    if os.path.exists(temp_model_path):
        os.remove(temp_model_path)
        print(f"ğŸ—‘ï¸  ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ: {temp_model_path}")
    else:
        print(f"âš ï¸  ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {temp_model_path}")


def save_results_with_metadata(results_dir, submission_df, model_info):
    """ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    submission_path = os.path.join(results_dir, f"submission_{timestamp}.csv")
    submission_df.to_csv(submission_path, index=False)
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {submission_path}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'timestamp': timestamp,
        'model_info': model_info,
        'config': CFG,
        'submission_shape': submission_df.shape,
        'submission_stats': {
            'mean_prediction': float(submission_df['clicked'].mean()),
            'min_prediction': float(submission_df['clicked'].min()),
            'max_prediction': float(submission_df['clicked'].max()),
            'std_prediction': float(submission_df['clicked'].std())
        }
    }
    
    metadata_path = os.path.join(results_dir, f"metadata_{timestamp}.json")
    import json
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
    print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
    
    return submission_path, metadata_path


def print_progress(step, total_steps, description):
    """ì§„í–‰ìƒí™© í”„ë¦°íŠ¸ í•¨ìˆ˜"""
    progress = f"[{step}/{total_steps}]"
    print(f"\n{'='*20} {progress} {description} {'='*20}")
    print(f"â° ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def print_step_summary(step_name, details):
    """ë‹¨ê³„ë³„ ìš”ì•½ ì •ë³´ í”„ë¦°íŠ¸"""
    print(f"\nğŸ“‹ {step_name} ì™„ë£Œ:")
    for key, value in details.items():
        print(f"   â€¢ {key}: {value}")

def safe_execute_step(step_func, step_name, error_log_path, *args, **kwargs):
    """ì•ˆì „í•˜ê²Œ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ê³  ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê¹…"""
    try:
        return step_func(*args, **kwargs)
    except Exception as e:
        step_info = f"ë‹¨ê³„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {step_name}"
        log_error(e, error_log_path, step_info)
        raise


def main():
    """ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    total_steps = 11
    print("ğŸš€ í›ˆë ¨ â†’ ì˜ˆì¸¡ â†’ ê²°ê³¼ ì €ì¥ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    print("=" * 80)
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”§ ì´ ë‹¨ê³„: {total_steps}ë‹¨ê³„")
    
    # 1. ì´ˆê¸°í™”
    print_progress(1, total_steps, "ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
    # ì‹œë“œ ê³ ì •
    seed_everything(CFG['SEED'])
    print(f"Device: {device}")
    print_step_summary("ì´ˆê¸°í™”", {
        "Device": device,
        "Epochs": CFG['EPOCHS'],
        "Batch Size": CFG['BATCH_SIZE'],
        "Learning Rate": CFG['LEARNING_RATE'],
        "Data Loading": "ì „ì²´ ë°ì´í„° ì‚¬ìš©"
    })
    
    # 2. ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    print_progress(2, total_steps, "ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±")
    results_dir = create_results_directory()
    
    # ì—ëŸ¬ ë¡œê¹… ì„¤ì •
    error_log_path = setup_error_logging(results_dir)
    
    print_step_summary("ë””ë ‰í† ë¦¬ ìƒì„±", {
        "Results Dir": results_dir,
        "Error Log": os.path.basename(error_log_path)
    })
    
    # 3. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    temp_model_path = CFG['PATHS']['TEMP_MODEL'].replace('{datetime}', timestamp)
    print(f"ğŸ“ ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ê²½ë¡œ: {temp_model_path}")
    
    try:
        # 4. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        print_progress(3, total_steps, "ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
        print(f"ğŸ’¾ ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        # ì „ì²´ ë°ì´í„° ë¡œë“œ (í›ˆë ¨ ì‹œ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ì„ ìœ„í•œ ë‹¤ìš´ìƒ˜í”Œë§ ì ìš©)
        train_data, test_data, feature_cols, seq_col, target_col = load_and_preprocess_data()
        print(f"ğŸ’¾ ë°ì´í„° ë¡œë“œ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        print_step_summary("ë°ì´í„° ë¡œë“œ", {
            "Train Shape": train_data.shape,
            "Test Shape": test_data.shape,
            "Features": len(feature_cols),
            "Sequence Column": seq_col,
            "Target Column": target_col,
            "Test ID Column": "ID" in test_data.columns,
            "Data Loading": "ì „ì²´ ë°ì´í„° ì‚¬ìš©",
            "Class Balancing": "ë‹¤ìš´ìƒ˜í”Œë§ ì ìš©",
            "Memory Usage": f"{get_memory_usage():.1f} MB"
        })
        
        # 5. ëª¨ë¸ í›ˆë ¨
        print_progress(4, total_steps, "ëª¨ë¸ í›ˆë ¨")
        print(f"ğŸ‹ï¸ ëª¨ë¸ ì„¤ì •:")
        print(f"   â€¢ Type: TabularTransformer")
        print(f"   â€¢ Hidden Dim: {CFG['MODEL']['TRANSFORMER']['HIDDEN_DIM']}")
        print(f"   â€¢ N Heads: {CFG['MODEL']['TRANSFORMER']['N_HEADS']}")
        print(f"   â€¢ N Layers: {CFG['MODEL']['TRANSFORMER']['N_LAYERS']}")
        print(f"   â€¢ LSTM Hidden: {CFG['MODEL']['TRANSFORMER']['LSTM_HIDDEN']}")
        
        model = train_model(
            train_df=train_data,
            feature_cols=feature_cols,
            seq_col=seq_col,
            target_col=target_col,
            device=device
        )
        print_step_summary("ëª¨ë¸ í›ˆë ¨", {
            "Model Type": "TabularTransformer",
            "Epochs Completed": CFG['EPOCHS'],
            "Device Used": device,
            "Checkpoint Interval": "Every 5 epochs"
        })
        
        # 6. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì €ì¥
        print_progress(5, total_steps, "ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì €ì¥")
        save_model(model, temp_model_path)
        print_step_summary("ì›¨ì´íŠ¸ ì €ì¥", {"File Path": temp_model_path})
        
        # 6.5. í›ˆë ¨ ë°ì´í„° ë©”ëª¨ë¦¬ì—ì„œ ì œê±°
        print_progress(6, total_steps, "í›ˆë ¨ ë°ì´í„° ë©”ëª¨ë¦¬ ì •ë¦¬")
        print(f"ğŸ’¾ í›ˆë ¨ ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        # í›ˆë ¨ì— í•„ìš”í•œ ì •ë³´ë§Œ ì €ì¥
        train_shape = train_data.shape
        model_info_data = {
            'train_shape': train_shape,
            'test_shape': test_data.shape,
            'num_features': len(feature_cols)
        }
        
        # í›ˆë ¨ ë°ì´í„° ë©”ëª¨ë¦¬ì—ì„œ ì œê±°
        cleanup_train_data(train_data, test_data)
        print_step_summary("ë©”ëª¨ë¦¬ ì •ë¦¬", {
            "Train Data": "ë©”ëª¨ë¦¬ì—ì„œ ì œê±°ë¨",
            "Test Data": "ìœ ì§€ë¨ (ì˜ˆì¸¡ì— í•„ìš”)",
            "Memory Usage": f"{get_memory_usage():.1f} MB"
        })
        
        # 7. ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘
        print_progress(7, total_steps, "ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘")
        model_info = {
            'model_type': 'tabular_transformer',
            'hidden_dim': CFG['MODEL']['TRANSFORMER']['HIDDEN_DIM'],
            'n_heads': CFG['MODEL']['TRANSFORMER']['N_HEADS'],
            'n_layers': CFG['MODEL']['TRANSFORMER']['N_LAYERS'],
            'lstm_hidden': CFG['MODEL']['TRANSFORMER']['LSTM_HIDDEN'],
            'epochs': CFG['EPOCHS'],
            'learning_rate': CFG['LEARNING_RATE'],
            'batch_size': CFG['BATCH_SIZE'],
            'train_shape': model_info_data['train_shape'],
            'test_shape': model_info_data['test_shape'],
            'num_features': model_info_data['num_features'],
            'early_stopping': CFG['EARLY_STOPPING']['ENABLED'],
            'monitor_metric': CFG['EARLY_STOPPING']['MONITOR'],
            'patience': CFG['EARLY_STOPPING']['PATIENCE']
        }
        print_step_summary("ì •ë³´ ìˆ˜ì§‘", {
            "Model Parameters": len(model_info),
            "Training Data Shape": model_info_data['train_shape'],
            "Test Data Shape": model_info_data['test_shape']
        })
        
        # 8. ì˜ˆì¸¡ ì‹¤í–‰
        print_progress(8, total_steps, "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡")
        print(f"ğŸ”® ì˜ˆì¸¡ ì„¤ì •:")
        print(f"   â€¢ Test Data Shape: {test_data.shape}")
        print(f"   â€¢ Features: {len(feature_cols)}")
        print(f"   â€¢ Batch Size: {CFG['BATCH_SIZE']}")
        print(f"ğŸ’¾ ì˜ˆì¸¡ ì „ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        submission_df = predict_test_data(
            test_data=test_data,
            feature_cols=feature_cols,
            seq_col=seq_col,
            model_path=temp_model_path,
            device=device
        )
        print(f"ğŸ’¾ ì˜ˆì¸¡ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        
        print_step_summary("ì˜ˆì¸¡ ì™„ë£Œ", {
            "Submission Shape": submission_df.shape,
            "Mean Prediction": f"{submission_df['clicked'].mean():.4f}",
            "Min Prediction": f"{submission_df['clicked'].min():.4f}",
            "Max Prediction": f"{submission_df['clicked'].max():.4f}",
            "Memory Usage": f"{get_memory_usage():.1f} MB"
        })
        
        # 9. ê²°ê³¼ ì €ì¥
        print_progress(9, total_steps, "ê²°ê³¼ ë° ë©”íƒ€ë°ì´í„° ì €ì¥")
        submission_path, metadata_path = save_results_with_metadata(
            results_dir, submission_df, model_info
        )
        print_step_summary("ê²°ê³¼ ì €ì¥", {
            "Submission File": submission_path,
            "Metadata File": metadata_path,
            "Results Directory": results_dir
        })
        
        # 10. ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ìš”ì•½
        print_progress(10, total_steps, "ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ìš”ì•½")
        print(f"ğŸ’¾ ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB")
        print("\nâœ… ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
        print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼: {submission_path}")
        print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°: {metadata_path}")
        print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ì—ëŸ¬ ë¡œê¹…
        step_info = f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
        log_error(e, error_log_path, step_info)
        
        # ì—ëŸ¬ ìš”ì•½ ì €ì¥
        save_error_summary(results_dir, error_log_path)
        
        print(f"ğŸ” ìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        print(f"\nğŸ“‹ ì—ëŸ¬ ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜: {error_log_path}")
        raise
    
    finally:
        # 11. ì„ì‹œ ì›¨ì´íŠ¸ íŒŒì¼ ì‚­ì œ
        print_progress(11, total_steps, "ì •ë¦¬ ì‘ì—…")
        cleanup_temp_files(temp_model_path)
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)
    print(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
