#!/usr/bin/env python3
"""
ëª¨ë“  Missing Pattern ê²€ì¦ - Pattern 1, 2, 3 ëª¨ë‘
"""

import pandas as pd
import numpy as np
import json

def validate_all_patterns():
    """ëª¨ë“  íŒ¨í„´ ê²€ì¦"""
    
    print("=" * 80)
    print("ëª¨ë“  Missing Pattern ê²€ì¦")
    print("=" * 80)
    print()
    
    # ê° íŒ¨í„´ì˜ ëŒ€í‘œ features ì„ íƒ
    pattern_features = {
        'pattern_1': ['gender', 'age_group', 'l_feat_2', 'feat_e_1', 'history_a_1'],  # 17,208 missing
        'pattern_2': ['feat_a_1', 'feat_a_2', 'feat_a_3', 'feat_a_4', 'feat_a_5'],   # 18,598 missing
        'pattern_3': ['feat_e_3']  # 1,085,557 missing
    }
    
    # ëª¨ë“  features í•©ì¹˜ê¸°
    all_features = []
    for features in pattern_features.values():
        all_features.extend(features)
    
    print(f"ê²€ì¦í•  features: {len(all_features)}ê°œ")
    for pattern, features in pattern_features.items():
        print(f"  {pattern}: {features}")
    print()
    
    try:
        print("ğŸ” ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ì„ íƒëœ ì»¬ëŸ¼ë§Œ ë¡œë“œ
        df = pd.read_parquet(
            '/Users/seunghoon/Library/Mobile Documents/com~apple~CloudDocs/Research/toss/train.parquet',
            columns=all_features
        )
        
        print(f"ë¡œë“œ ì™„ë£Œ: {len(df):,} rows, {len(df.columns)} columns")
        print()
        
        # ê° íŒ¨í„´ë³„ ê²€ì¦
        results = {}
        
        for pattern_name, features in pattern_features.items():
            print(f"ğŸ“Š {pattern_name.upper()} ê²€ì¦:")
            print("-" * 40)
            
            # í•´ë‹¹ íŒ¨í„´ì˜ featuresë§Œ ì„ íƒ
            pattern_df = df[features]
            
            # ê° featureë³„ missing count
            missing_counts = pattern_df.isnull().sum()
            print("Featureë³„ missing count:")
            for feature, count in missing_counts.items():
                percentage = (count / len(df)) * 100
                print(f"  {feature}: {count:,} ({percentage:.3f}%)")
            
            # ëª¨ë“  featuresê°€ ë™ì‹œì— missingì¸ í–‰
            all_missing = pattern_df.isnull().all(axis=1)
            all_missing_count = all_missing.sum()
            all_missing_percentage = (all_missing_count / len(df)) * 100
            
            # í•˜ë‚˜ë¼ë„ missingì¸ í–‰
            any_missing = pattern_df.isnull().any(axis=1)
            any_missing_count = any_missing.sum()
            any_missing_percentage = (any_missing_count / len(df)) * 100
            
            # ë¶€ë¶„ì ìœ¼ë¡œë§Œ missingì¸ í–‰
            partial_missing_count = any_missing_count - all_missing_count
            
            print(f"\nMissing íŒ¨í„´:")
            print(f"  ëª¨ë“  features ë™ì‹œ missing: {all_missing_count:,} ({all_missing_percentage:.3f}%)")
            print(f"  í•˜ë‚˜ë¼ë„ missing: {any_missing_count:,} ({any_missing_percentage:.3f}%)")
            print(f"  ë¶€ë¶„ì ìœ¼ë¡œë§Œ missing: {partial_missing_count:,}")
            
            # ì˜ˆìƒê°’ê³¼ ë¹„êµ
            expected_counts = {
                'pattern_1': 17208,
                'pattern_2': 18598,
                'pattern_3': 1085557
            }
            
            expected = expected_counts[pattern_name]
            expected_percentage = (expected / len(df)) * 100
            difference = abs(all_missing_count - expected)
            
            print(f"\nì˜ˆìƒê°’ê³¼ ë¹„êµ:")
            print(f"  ì˜ˆìƒ: {expected:,} ({expected_percentage:.3f}%)")
            print(f"  ì‹¤ì œ: {all_missing_count:,} ({all_missing_percentage:.3f}%)")
            print(f"  ì°¨ì´: {difference:,}")
            
            # ê²°ë¡ 
            if difference < 100:
                conclusion = "CONFIRMED"
                print(f"  âœ… í™•ì¸ë¨! ë™ì¼í•œ í–‰ì—ì„œ ëª¨ë“  features ë™ì‹œ missing")
            elif difference < expected * 0.01:  # 1% ì´ë‚´
                conclusion = "MOSTLY_CONFIRMED"
                print(f"  âš ï¸  ê±°ì˜ í™•ì¸ë¨ (1% ì´ë‚´ ì°¨ì´)")
            else:
                conclusion = "REJECTED"
                print(f"  âŒ ë¶ˆì¼ì¹˜")
            
            # ê²°ê³¼ ì €ì¥
            results[pattern_name] = {
                'features': features,
                'feature_missing_counts': missing_counts.to_dict(),
                'all_missing_together': int(all_missing_count),
                'any_missing': int(any_missing_count),
                'partial_missing': int(partial_missing_count),
                'expected': expected,
                'difference': int(difference),
                'conclusion': conclusion
            }
            
            print()
        
        # íŒ¨í„´ ê°„ ì¤‘ë³µ ë¶„ì„
        print("ğŸ” íŒ¨í„´ ê°„ ì¤‘ë³µ ë¶„ì„:")
        print("-" * 40)
        
        # ê° íŒ¨í„´ë³„ missing indicator ìƒì„±
        pattern_indicators = {}
        for pattern_name, features in pattern_features.items():
            pattern_df = df[features]
            if len(features) > 1:
                pattern_indicators[pattern_name] = pattern_df.isnull().all(axis=1)
            else:
                pattern_indicators[pattern_name] = pattern_df.isnull().iloc[:, 0]
        
        # íŒ¨í„´ ê°„ ì¤‘ë³µ ê³„ì‚°
        overlaps = {}
        pattern_names = list(pattern_indicators.keys())
        
        for i, p1 in enumerate(pattern_names):
            for p2 in pattern_names[i+1:]:
                overlap_key = f"{p1}_and_{p2}"
                overlap = pattern_indicators[p1] & pattern_indicators[p2]
                overlap_count = overlap.sum()
                overlap_percentage = (overlap_count / len(df)) * 100
                
                overlaps[overlap_key] = int(overlap_count)
                
                print(f"{p1} âˆ© {p2}: {overlap_count:,} rows ({overlap_percentage:.3f}%)")
                
                # ì¤‘ë³µë¥  ê³„ì‚°
                p1_count = pattern_indicators[p1].sum()
                p2_count = pattern_indicators[p2].sum()
                
                if p1_count > 0 and p2_count > 0:
                    overlap_rate_p1 = (overlap_count / p1_count) * 100
                    overlap_rate_p2 = (overlap_count / p2_count) * 100
                    print(f"  ì¤‘ë³µë¥ : {p1}ì˜ {overlap_rate_p1:.1f}%, {p2}ì˜ {overlap_rate_p2:.1f}%")
        
        print()
        
        # ì „ì²´ ê²°ë¡ 
        print("ğŸ¯ ì „ì²´ ê²°ë¡ :")
        print("-" * 40)
        
        confirmed_patterns = [p for p, r in results.items() if r['conclusion'] in ['CONFIRMED', 'MOSTLY_CONFIRMED']]
        
        print(f"í™•ì¸ëœ íŒ¨í„´: {len(confirmed_patterns)}ê°œ / {len(results)}ê°œ")
        
        for pattern_name, result in results.items():
            status = "âœ…" if result['conclusion'] == 'CONFIRMED' else "âš ï¸" if result['conclusion'] == 'MOSTLY_CONFIRMED' else "âŒ"
            print(f"  {pattern_name}: {status} {result['conclusion']}")
        
        print()
        
        if len(confirmed_patterns) == len(results):
            print("âœ… **ëª¨ë“  íŒ¨í„´ì´ í™•ì¸ë¨!**")
            print("   â†’ ê° íŒ¨í„´ë³„ë¡œ ë™ì¼í•œ í–‰ì—ì„œ í•´ë‹¹ featuresë“¤ì´ ëª¨ë‘ missing")
            print("   â†’ ì²´ê³„ì ì´ê³  ê·œì¹™ì ì¸ missing pattern")
        else:
            print("âš ï¸  **ì¼ë¶€ íŒ¨í„´ë§Œ í™•ì¸ë¨**")
            print("   â†’ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ")
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        final_results = {
            'validation_summary': {
                'total_patterns_tested': len(results),
                'confirmed_patterns': len(confirmed_patterns),
                'confirmed_pattern_names': confirmed_patterns
            },
            'pattern_results': results,
            'pattern_overlaps': overlaps,
            'key_findings': [
                f"Pattern 1: {results['pattern_1']['conclusion']} - 17,208ê°œ í–‰ì—ì„œ 77ê°œ features ëª¨ë‘ missing",
                f"Pattern 2: {results['pattern_2']['conclusion']} - 18,598ê°œ í–‰ì—ì„œ 18ê°œ features ëª¨ë‘ missing", 
                f"Pattern 3: {results['pattern_3']['conclusion']} - 1,085,557ê°œ í–‰ì—ì„œ 1ê°œ feature missing"
            ]
        }
        
        output_file = '/Users/seunghoon/Library/Mobile Documents/com~apple~CloudDocs/Research/toss/analysis/results/all_patterns_validation.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ ì „ì²´ ê²€ì¦ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
        
    except Exception as e:
        print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    validate_all_patterns()
