#!/usr/bin/env python3
"""
XGBoost ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, mean_squared_error
from xgboost_model import create_xgboost_model

def create_sample_data(n_samples=10000, n_categorical=5, n_numerical=20):
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹œí€€ìŠ¤ í”¼ì²˜ ì œì™¸)"""
    np.random.seed(42)
    
    # ë²”ì£¼í˜• í”¼ì²˜ ìƒì„±
    categorical_data = {}
    for i in range(n_categorical):
        categories = [f'cat_{i}_val_{j}' for j in range(np.random.randint(3, 10))]
        categorical_data[f'cat_{i}'] = np.random.choice(categories, n_samples)
    
    # ìˆ˜ì¹˜í˜• í”¼ì²˜ ìƒì„±
    numerical_data = {}
    for i in range(n_numerical):
        numerical_data[f'num_{i}'] = np.random.normal(0, 1, n_samples)
    
    # íƒ€ê²Ÿ ìƒì„± (ë²”ì£¼í˜•ê³¼ ìˆ˜ì¹˜í˜• í”¼ì²˜ì˜ ì¡°í•©ìœ¼ë¡œ)
    target = np.zeros(n_samples)
    for i in range(n_categorical):
        target += pd.Categorical(categorical_data[f'cat_{i}']).codes * 0.1
    for i in range(n_numerical):
        target += numerical_data[f'num_{i}'] * 0.05
    
    # sigmoid ì ìš©í•˜ì—¬ í™•ë¥ ë¡œ ë³€í™˜
    target_probs = 1 / (1 + np.exp(-target))
    target_binary = (target_probs > 0.5).astype(int)
    
    # DataFrame ìƒì„±
    data = {**categorical_data, **numerical_data, 'target': target_binary}
    df = pd.DataFrame(data)
    
    return df

def test_xgboost_model():
    """XGBoost ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª XGBoost ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    print("ğŸ“Š ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘...")
    df = create_sample_data(n_samples=10000, n_categorical=5, n_numerical=20)
    print(f"   â€¢ ë°ì´í„° í¬ê¸°: {df.shape}")
    print(f"   â€¢ íƒ€ê²Ÿ ë¶„í¬: {df['target'].value_counts().to_dict()}")
    
    # ë²”ì£¼í˜•ê³¼ ìˆ˜ì¹˜í˜• í”¼ì²˜ ë¶„ë¦¬
    categorical_features = [col for col in df.columns if col.startswith('cat_')]
    numerical_features = [col for col in df.columns if col.startswith('num_')]
    
    print(f"   â€¢ ë²”ì£¼í˜• í”¼ì²˜: {len(categorical_features)}ê°œ")
    print(f"   â€¢ ìˆ˜ì¹˜í˜• í”¼ì²˜: {len(numerical_features)}ê°œ")
    
    # í›ˆë ¨/ê²€ì¦ ë¶„í• 
    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])
    
    print(f"   â€¢ í›ˆë ¨ ë°ì´í„°: {len(train_df)}ê°œ")
    print(f"   â€¢ ê²€ì¦ ë°ì´í„°: {len(val_df)}ê°œ")
    
    # í”¼ì²˜ ì¤€ë¹„
    train_categorical = train_df[categorical_features]
    train_numerical = train_df[numerical_features]
    train_y = train_df['target'].values
    
    val_categorical = val_df[categorical_features]
    val_numerical = val_df[numerical_features]
    val_y = val_df['target'].values
    
    # XGBoost ëª¨ë¸ ìƒì„±
    print("\nğŸ”§ XGBoost ëª¨ë¸ ìƒì„± ì¤‘...")
    xgb_params = {
        'n_estimators': 100,
        'max_depth': 6,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 1.0,
        'random_state': 42,
        'n_jobs': -1,
        'early_stopping_rounds': 20,
        'eval_metric': 'rmse'
    }
    
    model = create_xgboost_model(xgb_params)
    print(f"   â€¢ ëª¨ë¸ íŒŒë¼ë¯¸í„°: {xgb_params}")
    
    # ëª¨ë¸ í›ˆë ¨
    print("\nğŸš€ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
    model.fit(
        X_categorical=train_categorical,
        X_numerical=train_numerical,
        y=train_y,
        X_val_categorical=val_categorical,
        X_val_numerical=val_numerical,
        y_val=val_y
    )
    print("   âœ… í›ˆë ¨ ì™„ë£Œ!")
    
    # ì˜ˆì¸¡
    print("\nğŸ”® ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    val_predictions = model.predict(
        X_categorical=val_categorical,
        X_numerical=val_numerical
    )
    print(f"   â€¢ ì˜ˆì¸¡ ê²°ê³¼ shape: {val_predictions.shape}")
    
    # ì„±ëŠ¥ í‰ê°€
    val_rmse = np.sqrt(mean_squared_error(val_y, val_predictions))
    val_probs = 1 / (1 + np.exp(-val_predictions))  # sigmoid
    val_auc = roc_auc_score(val_y, val_probs)
    
    print(f"\nğŸ“Š ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:")
    print(f"   â€¢ ê²€ì¦ RMSE: {val_rmse:.6f}")
    print(f"   â€¢ ê²€ì¦ AUC: {val_auc:.6f}")
    
    # ëª¨ë¸ ì €ì¥/ë¡œë“œ í…ŒìŠ¤íŠ¸
    print("\nğŸ’¾ ëª¨ë¸ ì €ì¥/ë¡œë“œ í…ŒìŠ¤íŠ¸ ì¤‘...")
    model.save("test_xgboost_model.pkl")
    print("   âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
    
    # ìƒˆ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¡œ ë¡œë“œ
    new_model = create_xgboost_model()
    new_model.load("test_xgboost_model.pkl")
    print("   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    
    # ë¡œë“œëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡
    loaded_predictions = new_model.predict(
        X_categorical=val_categorical,
        X_numerical=val_numerical
    )
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ
    predictions_match = np.allclose(val_predictions, loaded_predictions, rtol=1e-10)
    print(f"   â€¢ ì˜ˆì¸¡ ê²°ê³¼ ì¼ì¹˜: {predictions_match}")
    
    # ì •ë¦¬
    import os
    if os.path.exists("test_xgboost_model.pkl"):
        os.remove("test_xgboost_model.pkl")
        print("   ğŸ—‘ï¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ!")
    
    print("\nğŸ‰ XGBoost ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return val_auc

if __name__ == "__main__":
    test_xgboost_model()
