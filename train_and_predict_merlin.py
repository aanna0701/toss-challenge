#!/usr/bin/env python3
"""
NVIDIA Merlinì„ í™œìš©í•œ ê³ ì„±ëŠ¥ í›ˆë ¨ ë° ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš°
"""

import argparse
import gc
import json
import logging
import os
import psutil
import time
import traceback
from datetime import datetime

import yaml
import pandas as pd
import numpy as np
import torch
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, roc_auc_score

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def parse_args():
    """ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='NVIDIA Merlin ê¸°ë°˜ ê³ ì„±ëŠ¥ í›ˆë ¨ ë° ì˜ˆì¸¡ ì›Œí¬í”Œë¡œìš°')
    parser.add_argument('--config', type=str, default='config_fold1.yaml',
                       help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config_fold1.yaml)')
    parser.add_argument('--use-merlin', action='store_true', default=True,
                       help='NVIDIA Merlin ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)')
    parser.add_argument('--model-type', type=str, default='transformer',
                       choices=['transformer', 'xgboost'],
                       help='ëª¨ë¸ íƒ€ì… (ê¸°ë³¸ê°’: transformer)')
    return parser.parse_args()

def load_config(config_path):
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    logger.info(f"ğŸ“‹ ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
    return config

# ëª…ë ¹í–‰ ì¸ìˆ˜ íŒŒì‹± ë° ì„¤ì • ë¡œë“œ
args = parse_args()
CFG = load_config(args.config)

from utils import seed_everything, get_device
from data_loader_merlin import (
    MerlinFeatureProcessor, 
    MerlinClickDataset, 
    create_merlin_dataloader,
    load_train_data_merlin,
    load_test_data_merlin,
    MERLIN_AVAILABLE
)

DEVICE = get_device()

def create_results_directory():
    """ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = CFG['PATHS']['RESULTS_DIR'].replace('{datetime}', timestamp)
    
    os.makedirs(results_dir, exist_ok=True)
    logger.info(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}")
    
    return results_dir

def train_transformer_model_merlin(train_df, CFG, results_dir, use_merlin=True):
    """Merlin ê¸°ë°˜ Transformer ëª¨ë¸ í›ˆë ¨"""
    logger.info(f"ğŸš€ Merlin ê¸°ë°˜ Transformer ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    logger.info(f"   â€¢ Merlin ì‚¬ìš©: {use_merlin and MERLIN_AVAILABLE}")
    
    # ë°ì´í„° ë¶„í• 
    tr_df, va_df = train_test_split(
        train_df, 
        test_size=CFG['VAL_SPLIT'], 
        random_state=42, 
        shuffle=True, 
        stratify=train_df['clicked']
    )
    
    logger.info(f"ğŸ“Š ë°ì´í„° ë¶„í•  ê²°ê³¼:")
    logger.info(f"   â€¢ í›ˆë ¨ ë°ì´í„°: {len(tr_df):,}ê°œ")
    logger.info(f"   â€¢ ê²€ì¦ ë°ì´í„°: {len(va_df):,}ê°œ")
    
    # í”¼ì²˜ í”„ë¡œì„¸ì„œ ìƒì„± ë° í•™ìŠµ
    logger.info("ğŸ”§ í”¼ì²˜ í”„ë¡œì„¸ì„œ í•™ìŠµ ì¤‘...")
    processor = MerlinFeatureProcessor(
        config=CFG,
        normalization_stats_path="analysis/results/normalization_stats.json",
        use_merlin=use_merlin and MERLIN_AVAILABLE
    )
    
    processor.fit(tr_df)
    
    # ë°ì´í„°ì…‹ ìƒì„±
    logger.info("ğŸ“Š ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    train_dataset = MerlinClickDataset(
        df=tr_df,
        feature_processor=processor,
        target_col='clicked',
        has_target=True,
        has_id=False,
        use_merlin=use_merlin and MERLIN_AVAILABLE
    )
    
    val_dataset = MerlinClickDataset(
        df=va_df,
        feature_processor=processor,
        target_col='clicked',
        has_target=True,
        has_id=False,
        use_merlin=use_merlin and MERLIN_AVAILABLE
    )
    
    # DataLoader ìƒì„±
    logger.info("ğŸš€ DataLoader ìƒì„± ì¤‘...")
    train_loader = create_merlin_dataloader(
        dataset=train_dataset,
        batch_size=CFG['BATCH_SIZE'],
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    
    val_loader = create_merlin_dataloader(
        dataset=val_dataset,
        batch_size=CFG['BATCH_SIZE'],
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    logger.info(f"âœ… DataLoader ìƒì„± ì™„ë£Œ:")
    logger.info(f"   â€¢ í›ˆë ¨ ë°°ì¹˜: {len(train_loader)}ê°œ")
    logger.info(f"   â€¢ ê²€ì¦ ë°°ì¹˜: {len(val_loader)}ê°œ")
    
    # ëª¨ë¸ ìƒì„±
    from model import create_model
    model = create_model(CFG).to(DEVICE)
    
    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
    criterion = torch.nn.BCEWithLogitsLoss()
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=CFG['LEARNING_RATE'],
        weight_decay=CFG['WEIGHT_DECAY']
    )
    
    # ìŠ¤ì¼€ì¤„ëŸ¬
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=CFG['EPOCHS']
    )
    
    # í›ˆë ¨ ë£¨í”„
    logger.info("ğŸš€ í›ˆë ¨ ì‹œì‘...")
    best_val_score = 0.0
    patience_counter = 0
    
    for epoch in range(1, CFG['EPOCHS'] + 1):
        # í›ˆë ¨
        model.train()
        train_loss = 0.0
        
        start_time = time.time()
        
        for batch_idx, batch in enumerate(train_loader):
            # GPUë¡œ ì´ë™
            x_categorical = batch['x_categorical'].to(DEVICE)
            x_numerical = batch['x_numerical'].to(DEVICE)
            seqs = batch['seqs'].to(DEVICE)
            seq_lengths = batch['seq_lengths'].to(DEVICE)
            ys = batch['ys'].to(DEVICE)
            
            optimizer.zero_grad()
            
            # ìˆœì „íŒŒ
            outputs = model(x_categorical, x_numerical, seqs, seq_lengths)
            loss = criterion(outputs.squeeze(), ys)
            
            # ì—­ì „íŒŒ
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
            if batch_idx % 100 == 0:
                logger.info(f"   Epoch {epoch}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.6f}")
        
        # ê²€ì¦
        model.eval()
        val_loss = 0.0
        val_predictions = []
        val_targets = []
        
        with torch.no_grad():
            for batch in val_loader:
                x_categorical = batch['x_categorical'].to(DEVICE)
                x_numerical = batch['x_numerical'].to(DEVICE)
                seqs = batch['seqs'].to(DEVICE)
                seq_lengths = batch['seq_lengths'].to(DEVICE)
                ys = batch['ys'].to(DEVICE)
                
                outputs = model(x_categorical, x_numerical, seqs, seq_lengths)
                loss = criterion(outputs.squeeze(), ys)
                
                val_loss += loss.item()
                
                # ì˜ˆì¸¡ê°’ ì €ì¥
                val_predictions.extend(torch.sigmoid(outputs.squeeze()).cpu().numpy())
                val_targets.extend(ys.cpu().numpy())
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        
        val_auc = roc_auc_score(val_targets, val_predictions)
        val_rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
        scheduler.step()
        
        epoch_time = time.time() - start_time
        
        logger.info(f"ğŸ“Š Epoch {epoch} ê²°ê³¼:")
        logger.info(f"   â€¢ í›ˆë ¨ ì†ì‹¤: {avg_train_loss:.6f}")
        logger.info(f"   â€¢ ê²€ì¦ ì†ì‹¤: {avg_val_loss:.6f}")
        logger.info(f"   â€¢ ê²€ì¦ AUC: {val_auc:.6f}")
        logger.info(f"   â€¢ ê²€ì¦ RMSE: {val_rmse:.6f}")
        logger.info(f"   â€¢ ì†Œìš” ì‹œê°„: {epoch_time:.2f}ì´ˆ")
        
        # ì¡°ê¸° ì¢…ë£Œ
        if CFG['EARLY_STOPPING']['ENABLED']:
            if val_auc > best_val_score + CFG['EARLY_STOPPING']['MIN_DELTA']:
                best_val_score = val_auc
                patience_counter = 0
                
                # ìµœê³  ëª¨ë¸ ì €ì¥
                model_path = os.path.join(results_dir, f"best_model_epoch_{epoch}.pth")
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_auc': val_auc,
                    'val_rmse': val_rmse,
                    'processor': processor
                }, model_path)
                logger.info(f"ğŸ’¾ ìµœê³  ëª¨ë¸ ì €ì¥: {model_path}")
            else:
                patience_counter += 1
                logger.info(f"â³ ì¡°ê¸° ì¢…ë£Œ ì¹´ìš´í„°: {patience_counter}/{CFG['EARLY_STOPPING']['PATIENCE']}")
                
                if patience_counter >= CFG['EARLY_STOPPING']['PATIENCE']:
                    logger.info("ğŸ›‘ ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ë§Œì¡±. í›ˆë ¨ ì¢…ë£Œ.")
                    break
    
    logger.info("âœ… Transformer ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    return model, processor

def predict_transformer_model_merlin(test_df, model, processor, CFG, results_dir, use_merlin=True):
    """Merlin ê¸°ë°˜ Transformer ëª¨ë¸ ì˜ˆì¸¡"""
    logger.info("ğŸ”® Merlin ê¸°ë°˜ Transformer ëª¨ë¸ ì˜ˆì¸¡ ì‹œì‘...")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
    test_dataset = MerlinClickDataset(
        df=test_df,
        feature_processor=processor,
        target_col='clicked',
        has_target=False,
        has_id=True,
        use_merlin=use_merlin and MERLIN_AVAILABLE
    )
    
    # í…ŒìŠ¤íŠ¸ DataLoader ìƒì„±
    test_loader = create_merlin_dataloader(
        dataset=test_dataset,
        batch_size=CFG['BATCH_SIZE'],
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ DataLoader ìƒì„± ì™„ë£Œ: {len(test_loader)}ê°œ ë°°ì¹˜")
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    model.eval()
    predictions = []
    ids = []
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(test_loader):
            x_categorical = batch['x_categorical'].to(DEVICE)
            x_numerical = batch['x_numerical'].to(DEVICE)
            seqs = batch['seqs'].to(DEVICE)
            seq_lengths = batch['seq_lengths'].to(DEVICE)
            batch_ids = batch['ids']
            
            outputs = model(x_categorical, x_numerical, seqs, seq_lengths)
            probs = torch.sigmoid(outputs.squeeze())
            
            predictions.extend(probs.cpu().numpy())
            ids.extend(batch_ids)
            
            if batch_idx % 100 == 0:
                logger.info(f"   ë°°ì¹˜ {batch_idx}/{len(test_loader)} ì²˜ë¦¬ ì™„ë£Œ")
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission_df = pd.DataFrame({
        'id': ids,
        'clicked': predictions
    })
    
    submission_path = os.path.join(results_dir, f"merlin_submission_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
    submission_df.to_csv(submission_path, index=False)
    
    logger.info(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
    logger.info(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:")
    logger.info(f"   â€¢ Shape: {submission_df.shape}")
    logger.info(f"   â€¢ Min: {submission_df['clicked'].min():.4f}")
    logger.info(f"   â€¢ Max: {submission_df['clicked'].max():.4f}")
    logger.info(f"   â€¢ Mean: {submission_df['clicked'].mean():.4f}")
    logger.info(f"ğŸ’¾ ì œì¶œ íŒŒì¼ ì €ì¥: {submission_path}")
    
    return submission_df

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        logger.info("ğŸš€ NVIDIA Merlin ê¸°ë°˜ ê³ ì„±ëŠ¥ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
        logger.info("=" * 60)
        
        # Merlin ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if args.use_merlin and not MERLIN_AVAILABLE:
            logger.warning("âš ï¸  NVIDIA Merlinì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í‘œì¤€ ë°ì´í„°ë¡œë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            args.use_merlin = False
        
        logger.info(f"ğŸ”§ ì„¤ì • ì •ë³´:")
        logger.info(f"   â€¢ Merlin ì‚¬ìš©: {args.use_merlin and MERLIN_AVAILABLE}")
        logger.info(f"   â€¢ ëª¨ë¸ íƒ€ì…: {args.model_type}")
        logger.info(f"   â€¢ ë°°ì¹˜ í¬ê¸°: {CFG['BATCH_SIZE']}")
        logger.info(f"   â€¢ ì—í¬í¬: {CFG['EPOCHS']}")
        
        # ì‹œë“œ ì„¤ì •
        seed_everything(CFG['SEED'])
        logger.info(f"ğŸ² ì‹œë“œ ì„¤ì •: {CFG['SEED']}")
        
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        results_dir = create_results_directory()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        memory_info = psutil.virtual_memory()
        logger.info(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_info.percent:.1f}% ({memory_info.used / 1024**3:.1f}GB / {memory_info.total / 1024**3:.1f}GB)")
        
        if torch.cuda.is_available():
            logger.info(f"ğŸš€ GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
            logger.info(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        
        # í›ˆë ¨ ë°ì´í„° ë¡œë“œ
        logger.info("ğŸ“Š í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì¤‘...")
        train_df, feature_cols, seq_col, target_col = load_train_data_merlin(CFG)
        logger.info(f"   â€¢ í›ˆë ¨ ë°ì´í„° í¬ê¸°: {train_df.shape}")
        logger.info(f"   â€¢ í´ë˜ìŠ¤ ë¶„í¬: {train_df['clicked'].value_counts().to_dict()}")
        
        # ëª¨ë¸ë³„ í›ˆë ¨ ë° ì˜ˆì¸¡
        if args.model_type == 'transformer':
            # Transformer ëª¨ë¸ í›ˆë ¨
            model, processor = train_transformer_model_merlin(
                train_df, CFG, results_dir, args.use_merlin
            )
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
            logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
            test_df = load_test_data_merlin(CFG)
            logger.info(f"   â€¢ í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {test_df.shape}")
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            submission_df = predict_transformer_model_merlin(
                test_df, model, processor, CFG, results_dir, args.use_merlin
            )
            
        elif args.model_type == 'xgboost':
            logger.info("ğŸš€ XGBoost ëª¨ë¸ì€ ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”: train_and_predict_xgboost.py")
            return 0
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'model_type': args.model_type,
            'use_merlin': args.use_merlin and MERLIN_AVAILABLE,
            'config': CFG,
            'timestamp': datetime.now().isoformat(),
            'submission_shape': submission_df.shape,
            'device': str(DEVICE)
        }
        
        metadata_path = os.path.join(results_dir, f"merlin_metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
        
        logger.info("ğŸ‰ Merlin ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")
        logger.info(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {results_dir}")
        
        return 0
        
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error("ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)
