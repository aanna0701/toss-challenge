import pandas as pd
import torch
from tqdm import tqdm
from torch.utils.data import DataLoader

from main import CFG, device, initialize
from data_loader import load_and_preprocess_data, ClickDataset, TabularSeqDataset, collate_fn_seq_infer, collate_fn_transformer_infer, FeatureProcessor
from model import *


def predict(model, test_loader, device="cuda", model_type="tabular_seq"):
    """ì˜ˆì¸¡ í•¨ìˆ˜ - ë”•ì…”ë„ˆë¦¬ ë°°ì¹˜ì—ì„œ IDì™€ ì˜ˆì¸¡ê°’ì„ í•¨ê»˜ ë°˜í™˜"""
    model.eval()
    predictions = []
    ids = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Inference"):
            batch_ids = batch.get('ids', [])  # collate_fnì—ì„œ ì´ë¯¸ ê²€ì¦ë¨
            ids.extend(batch_ids)
            
            if model_type == 'tabular_seq':
                # TabularSeq ëª¨ë¸ìš© ë°°ì¹˜ ì²˜ë¦¬
                xs = batch.get('xs').to(device)
                seqs = batch.get('seqs').to(device)
                seq_lengths = batch.get('seq_lengths').to(device)
                logits = model(xs, seqs, seq_lengths)
            elif model_type == 'tabular_transformer':
                # Transformer ëª¨ë¸ìš© ë°°ì¹˜ ì²˜ë¦¬
                x_categorical = batch.get('x_categorical').to(device)
                x_numerical = batch.get('x_numerical').to(device)
                seqs = batch.get('seqs').to(device)
                seq_lengths = batch.get('seq_lengths').to(device)
                nan_mask = batch.get('nan_mask').to(device)
                logits = model(
                    x_categorical=x_categorical,
                    x_numerical=x_numerical,
                    x_seq=seqs,
                    seq_lengths=seq_lengths,
                    nan_mask=nan_mask
                )
            
            probs = torch.sigmoid(logits)
            predictions.append(probs.cpu())
    
    predictions_array = torch.cat(predictions).numpy()
    
    # IDì™€ ì˜ˆì¸¡ê°’ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
    result = {
        'ids': ids,
        'predictions': predictions_array
    }
    
    return result

def create_submission(prediction_result, output_path=None):
    """ì œì¶œ íŒŒì¼ ìƒì„± í•¨ìˆ˜ - ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°›ìŒ"""
    if output_path is None:
        output_path = CFG['PATHS']['SUBMISSION']
    
    # ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ IDì™€ predictions ì¶”ì¶œ
    ids = prediction_result['ids']
    predictions = prediction_result['predictions']
    
    # ê²€ì¦
    if not ids:
        raise ValueError("âŒ ID ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤!")
    
    if len(ids) != len(predictions):
        raise ValueError(f"âŒ ID ê°œìˆ˜({len(ids)})ì™€ ì˜ˆì¸¡ ê²°ê³¼ ê°œìˆ˜({len(predictions)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
    
    submit = pd.DataFrame({
        'ID': ids,
        'clicked': predictions
    })
    
    print("âœ… IDì™€ ì˜ˆì¸¡ê°’ ë§¤ì¹­ ì™„ë£Œ")
    submit.to_csv(output_path, index=False)
    print(f"Submission file saved to {output_path}")
    print(f"Submission shape: {submit.shape}")
    return submit

def load_trained_model(feature_cols, model_path=None, device="cuda", model_type=None):
    """í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜"""
    if model_path is None:
        model_path = CFG['PATHS']['MODEL_SAVE']
    
    if model_type is None:
        model_type = CFG['MODEL']['TYPE']
    
    if model_type == 'tabular_seq':
        d_features = len(feature_cols)
        model = create_tabular_seq_model(
            d_features=d_features, 
            lstm_hidden=CFG['MODEL']['LSTM_HIDDEN'], 
            hidden_units=CFG['MODEL']['HIDDEN_UNITS'], 
            dropout=CFG['MODEL']['DROPOUT'], 
            device=device
        )
    elif model_type == 'tabular_transformer':
        # Transformer ëª¨ë¸ìš© í”¼ì²˜ ì •ë³´ (í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ FeatureProcessor í•„ìš”)
        # ì‹¤ì œë¡œëŠ” í›ˆë ¨ ì‹œ ì €ì¥ëœ feature_processor ì •ë³´ë¥¼ ë¡œë“œí•´ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ configì—ì„œ ê°€ì ¸ì˜´
        categorical_cardinalities = [2, 8, 20, 7, 24]  # gender, age_group, inventory_id, day_of_week, hour
        num_categorical_features = len(CFG['MODEL']['FEATURES']['CATEGORICAL'])
        num_numerical_features = len(feature_cols) - num_categorical_features - 1  # seq ì œì™¸
        
        model = create_tabular_transformer_model(
            num_categorical_features=num_categorical_features,
            categorical_cardinalities=categorical_cardinalities,
            num_numerical_features=num_numerical_features,
            lstm_hidden=CFG['MODEL']['TRANSFORMER']['LSTM_HIDDEN'],
            hidden_dim=CFG['MODEL']['TRANSFORMER']['HIDDEN_DIM'],
            n_heads=CFG['MODEL']['TRANSFORMER']['N_HEADS'],
            n_layers=CFG['MODEL']['TRANSFORMER']['N_LAYERS'],
            ffn_size_factor=CFG['MODEL']['TRANSFORMER']['FFN_SIZE_FACTOR'],
            attention_dropout=CFG['MODEL']['TRANSFORMER']['ATTENTION_DROPOUT'],
            ffn_dropout=CFG['MODEL']['TRANSFORMER']['FFN_DROPOUT'],
            residual_dropout=CFG['MODEL']['TRANSFORMER']['RESIDUAL_DROPOUT'],
            device=device
        )
    else:
        raise ValueError(f"Unknown model type: {model_type}")
    
    model.load_state_dict(torch.load(model_path, weights_only=True))
    print(f"Model loaded from {model_path}")
    return model

def run_inference(model, test_data, feature_cols, seq_col, batch_size, device="cuda", model_type="tabular_seq"):
    """ì¶”ë¡  ì‹¤í–‰ í•¨ìˆ˜"""
    if model_type == 'tabular_seq':
        # TabularSeq ëª¨ë¸ìš© ë°ì´í„°ì…‹
        test_dataset = TabularSeqDataset(test_data, feature_cols, seq_col, has_target=False, has_id=True)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_seq_infer)
    elif model_type == 'tabular_transformer':
        # Transformer ëª¨ë¸ìš© ë°ì´í„°ì…‹
        feature_processor = FeatureProcessor()
        feature_processor.fit(test_data)  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ fit (ì‹¤ì œë¡œëŠ” í›ˆë ¨ ë°ì´í„°ë¡œ fití•´ì•¼ í•¨)
        test_dataset = ClickDataset(test_data, feature_processor, has_target=False, has_id=True)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_transformer_infer)
    else:
        raise ValueError(f"Unknown model type: {model_type}")
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    prediction_result = predict(model, test_loader, device, model_type)
    
    return prediction_result

if __name__ == "__main__":
    # ì´ˆê¸°í™”
    initialize()
    
    # ë°ì´í„° ë¡œë“œ
    _, test_data, feature_cols, seq_col, target_col = load_and_preprocess_data()
    
    # í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ (train.pyì—ì„œ ì €ì¥ëœ ëª¨ë¸)
    try:
        model = load_trained_model(feature_cols, device=device)
    except FileNotFoundError:
        print("Trained model not found. Please run train.py first!")
        exit(1)
    
    # ì¶”ë¡  ì‹¤í–‰
    prediction_result = run_inference(
        model=model,
        test_data=test_data,
        feature_cols=feature_cols,
        seq_col=seq_col,
        batch_size=CFG['BATCH_SIZE'],
        device=device
    )
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission = create_submission(prediction_result)
    predictions = prediction_result['predictions']
    print("Prediction completed!")
    print(f"Prediction shape: {predictions.shape}")
    print(f"Prediction stats: min={predictions.min():.4f}, max={predictions.max():.4f}, mean={predictions.mean():.4f}")


def predict_test_data(test_data, feature_cols, seq_col, model_path=None, device="cuda"):
    model_type = CFG['MODEL']['TYPE']
    
    # ëª¨ë¸ ë¡œë“œ
    model = load_trained_model(feature_cols, model_path, device, model_type)
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    prediction_result = run_inference(
        model=model,
        test_data=test_data,
        feature_cols=feature_cols,
        seq_col=seq_col,
        batch_size=CFG['BATCH_SIZE'],
        device=device,
        model_type=model_type
    )
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission = create_submission(prediction_result)
    
    predictions = prediction_result['predictions']
    print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:")
    print(f"   - Shape: {predictions.shape}")
    print(f"   - Min: {predictions.min():.4f}")
    print(f"   - Max: {predictions.max():.4f}")
    print(f"   - Mean: {predictions.mean():.4f}")
    print(f"   - Std: {predictions.std():.4f}")
    
    return submission
