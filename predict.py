import pandas as pd
import torch
from tqdm import tqdm

from data_loader import (
    FeatureProcessor,
    ClickDataset,
    collate_fn_transformer_infer,
)
from torch.utils.data import DataLoader
from model import create_tabular_transformer_model, create_widedeep_ctr_model


def predict(model, test_loader, device, fabric=None):
    """ì˜ˆì¸¡ í•¨ìˆ˜ - ë”•ì…”ë„ˆë¦¬ ë°°ì¹˜ì—ì„œ IDì™€ ì˜ˆì¸¡ê°’ì„ í•¨ê»˜ ë°˜í™˜ (Lightning Fabric ì§€ì›)"""
    model.eval()
    predictions = []
    ids = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Inference"):
            batch_ids = batch.get('ids', [])  # collate_fnì—ì„œ ì´ë¯¸ ê²€ì¦ë¨
            ids.extend(batch_ids)
            
            # ë°°ì¹˜ ë°ì´í„° ì²˜ë¦¬ (Fabric ì§€ì›)
            # Fabricì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë°°ì¹˜ê°€ ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ë¨
            x_categorical = batch.get('x_categorical')
            x_numerical = batch.get('x_numerical')
            seqs = batch.get('seqs')
            seq_lengths = batch.get('seq_lengths')
            
            # Fabricì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì—ë§Œ ìˆ˜ë™ìœ¼ë¡œ ë””ë°”ì´ìŠ¤ ì´ë™
            if not fabric:
                x_categorical = x_categorical.to(device)
                x_numerical = x_numerical.to(device)
                seqs = seqs.to(device)
                seq_lengths = seq_lengths.to(device)
            
            # ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ forward í˜¸ì¶œ ë°©ì‹ ê²°ì •
            if hasattr(model, 'forward') and 'num_x' in model.forward.__code__.co_varnames:
                # WideDeepCTR ëª¨ë¸
                logits = model(
                    num_x=x_numerical,
                    cat_x=x_categorical,
                    seqs=seqs,
                    seq_lengths=seq_lengths
                )
            else:
                # TabularTransformer ëª¨ë¸
                logits = model(
                    x_categorical=x_categorical,
                    x_numerical=x_numerical,
                    x_seq=seqs,
                    seq_lengths=seq_lengths
                )
            
            probs = torch.sigmoid(logits)
            predictions.append(probs.cpu())
    
    predictions_array = torch.cat(predictions).numpy()
    
    # IDì™€ ì˜ˆì¸¡ê°’ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
    result = {
        'ids': ids,
        'predictions': predictions_array
    }
    
    return result

def create_submission(prediction_result, CFG, output_path):
    """ì œì¶œ íŒŒì¼ ìƒì„± í•¨ìˆ˜ - ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°›ìŒ"""
    
    # ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ IDì™€ predictions ì¶”ì¶œ
    ids = prediction_result['ids']
    predictions = prediction_result['predictions']
    
    # ê²€ì¦
    if not ids:
        raise ValueError("âŒ ID ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤!")
    
    if len(ids) != len(predictions):
        raise ValueError(f"âŒ ID ê°œìˆ˜({len(ids)})ì™€ ì˜ˆì¸¡ ê²°ê³¼ ê°œìˆ˜({len(predictions)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
    
    submit = pd.DataFrame({
        'ID': ids,
        'clicked': predictions
    })
    
    print("âœ… IDì™€ ì˜ˆì¸¡ê°’ ë§¤ì¹­ ì™„ë£Œ")
    submit.to_csv(output_path, index=False)
    print(f"Submission file saved to {output_path}")
    print(f"Submission shape: {submit.shape}")
    return submit

def load_trained_model(feature_processor, CFG, model_path, device):
    """í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜"""
    print(f"ğŸ”§ ëª¨ë¸ ë¡œë”© ì‹œì‘...")
    print(f"   â€¢ ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"   â€¢ ë””ë°”ì´ìŠ¤: {device}")
    
    # FeatureProcessorì—ì„œ í”¼ì²˜ ì •ë³´ ì¶”ì¶œ
    categorical_cardinalities = list(feature_processor.categorical_cardinalities.values())
    num_categorical_features = len(feature_processor.categorical_features)
    num_numerical_features = len(feature_processor.numerical_features)
    
    print(f"âœ… í”¼ì²˜ ì •ë³´:")
    print(f"   â€¢ ë²”ì£¼í˜• í”¼ì²˜: {num_categorical_features}ê°œ")
    print(f"   â€¢ ìˆ˜ì¹˜í˜• í”¼ì²˜: {num_numerical_features}ê°œ")
    print(f"   â€¢ ë²”ì£¼í˜• ì¹´ë””ë„ë¦¬í‹°: {categorical_cardinalities}")
    
    # ëª¨ë¸ íƒ€ì… ê²°ì •
    model_type = CFG.get('MODEL_TYPE', 'transformer')  # ê¸°ë³¸ê°’: transformer
    
    if model_type == 'widedeep':
        # WideDeepCTR ëª¨ë¸ ìƒì„±
        model = create_widedeep_ctr_model(
            num_features=num_numerical_features,
            cat_cardinalities=categorical_cardinalities,
            emb_dim=CFG['MODEL']['WIDEDEEP']['EMB_DIM'],
            lstm_hidden=CFG['MODEL']['WIDEDEEP']['LSTM_HIDDEN'],
            hidden_units=CFG['MODEL']['WIDEDEEP']['HIDDEN_UNITS'],
            dropout=CFG['MODEL']['WIDEDEEP']['DROPOUT'],
            device=device
        )
        model_type_name = "WideDeepCTR"
    else:
        # TabularTransformer ëª¨ë¸ ìƒì„± (ê¸°ë³¸ê°’)
        model = create_tabular_transformer_model(
            num_categorical_features=num_categorical_features,
            categorical_cardinalities=categorical_cardinalities,
            num_numerical_features=num_numerical_features,
            lstm_hidden=CFG['MODEL']['TRANSFORMER']['HIDDEN_DIM'],
            hidden_dim=CFG['MODEL']['TRANSFORMER']['HIDDEN_DIM'],
            n_heads=CFG['MODEL']['TRANSFORMER']['N_HEADS'],
            n_layers=CFG['MODEL']['TRANSFORMER']['N_LAYERS'],
            ffn_size_factor=CFG['MODEL']['TRANSFORMER']['FFN_SIZE_FACTOR'],
            attention_dropout=CFG['MODEL']['TRANSFORMER']['ATTENTION_DROPOUT'],
            ffn_dropout=CFG['MODEL']['TRANSFORMER']['FFN_DROPOUT'],
            residual_dropout=CFG['MODEL']['TRANSFORMER']['RESIDUAL_DROPOUT'],
            device=device
        )
        model_type_name = "TabularTransformer"
    
    print(f"âœ… ëª¨ë¸ íƒ€ì…: {model_type_name}")
    
    model.load_state_dict(torch.load(model_path, weights_only=True))
    print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {model_path}")
    
    # Best checkpointì¸ì§€ í™•ì¸
    if "best.pth" in model_path:
        print(f"ğŸ† Best checkpoint ì‚¬ìš© ì¤‘ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)")
    else:
        print(f"ğŸ“ ì¼ë°˜ checkpoint ì‚¬ìš© ì¤‘")
    
    return model

def predict_test_data(test_data, feature_processor, CFG, model_path, device, fabric=None):
    # FeatureProcessor ì§ì ‘ ìƒì„± ë° í…ŒìŠ¤íŠ¸ ë¡œë” ìƒì„±
    print("ğŸ”§ FeatureProcessor ë° í…ŒìŠ¤íŠ¸ ë¡œë” ìƒì„±...")
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
    test_dataset = ClickDataset(test_data, feature_processor, has_target=False, has_id=True)
    test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, collate_fn=collate_fn_transformer_infer)
    
    # Fabricì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° DataLoaderë¥¼ ë˜í•‘
    if fabric:
        print(f"ğŸ”§ í…ŒìŠ¤íŠ¸ DataLoaderë¥¼ Fabricìœ¼ë¡œ ë˜í•‘ ì¤‘...")
        test_loader = fabric.setup_dataloaders(test_loader)
        print(f"âœ… í…ŒìŠ¤íŠ¸ DataLoader Fabric ë˜í•‘ ì™„ë£Œ")
    
    # ëª¨ë¸ ë¡œë“œ
    model = load_trained_model(feature_processor, CFG, model_path, device)
    
    # ì˜ˆì¸¡ ìˆ˜í–‰ (test_loader ì§ì ‘ ì‚¬ìš©)
    prediction_result = predict(model, test_loader, device, fabric)
    
    # ì œì¶œ íŒŒì¼ ìƒì„± (ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥)
    import tempfile
    import os
    temp_submission_path = os.path.join(tempfile.gettempdir(), "temp_submission.csv")
    submission = create_submission(prediction_result, CFG=CFG, output_path=temp_submission_path)
    
    predictions = prediction_result['predictions']
    print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:")
    print(f"   - Shape: {predictions.shape}")
    print(f"   - Min: {predictions.min():.4f}")
    print(f"   - Max: {predictions.max():.4f}")
    print(f"   - Mean: {predictions.mean():.4f}")
    print(f"   - Std: {predictions.std():.4f}")
    
    return submission
