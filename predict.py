import pandas as pd
import torch
from tqdm import tqdm
from torch.utils.data import DataLoader

from main import CFG, device, initialize
from data_loader import load_and_preprocess_data, ClickDataset, collate_fn_infer
from model import *


def predict(model, test_loader, device="cuda"):
    """ì˜ˆì¸¡ í•¨ìˆ˜"""
    model.eval()
    predictions = []
    
    with torch.no_grad():
        for xs, seqs, lens in tqdm(test_loader, desc="Inference"):
            xs, seqs, lens = xs.to(device), seqs.to(device), lens.to(device)
            logits = model(xs, seqs, lens)
            probs = torch.sigmoid(logits)
            predictions.append(probs.cpu())
    
    return torch.cat(predictions).numpy()

def create_submission(predictions, output_path=None):
    """ì œì¶œ íŒŒì¼ ìƒì„± í•¨ìˆ˜"""
    if output_path is None:
        output_path = CFG['PATHS']['SUBMISSION']
    
    # ì˜ˆì¸¡ ê²°ê³¼ ê¸¸ì´ì— ë§ëŠ” ì œì¶œ íŒŒì¼ ìƒì„±
    submit = pd.DataFrame({
        'ID': range(len(predictions)),
        'clicked': predictions
    })
    
    submit.to_csv(output_path, index=False)
    print(f"Submission file saved to {output_path}")
    print(f"Submission shape: {submit.shape}")
    return submit

def load_trained_model(feature_cols, model_path=None, device="cuda"):
    """í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜"""
    if model_path is None:
        model_path = CFG['PATHS']['MODEL_SAVE']
    
    d_features = len(feature_cols)
    model = create_tabular_seq_model(
        d_features=d_features, 
        lstm_hidden=CFG['MODEL']['LSTM_HIDDEN'], 
        hidden_units=CFG['MODEL']['HIDDEN_UNITS'], 
        dropout=CFG['MODEL']['DROPOUT'], 
        device=device
    )
    model.load_state_dict(torch.load(model_path))
    print(f"Model loaded from {model_path}")
    return model

def run_inference(model, test_data, feature_cols, seq_col, batch_size, device="cuda"):
    """ì¶”ë¡  ì‹¤í–‰ í•¨ìˆ˜"""
    # Test dataset ìƒì„±
    test_dataset = ClickDataset(test_data, feature_cols, seq_col, has_target=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_infer)
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = predict(model, test_loader, device)
    
    return predictions

if __name__ == "__main__":
    # ì´ˆê¸°í™”
    initialize()
    
    # ë°ì´í„° ë¡œë“œ
    _, test_data, feature_cols, seq_col, target_col = load_and_preprocess_data()
    
    # í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ (train.pyì—ì„œ ì €ì¥ëœ ëª¨ë¸)
    try:
        model = load_trained_model(feature_cols, device=device)
    except FileNotFoundError:
        print("Trained model not found. Please run train.py first!")
        exit(1)
    
    # ì¶”ë¡  ì‹¤í–‰
    predictions = run_inference(
        model=model,
        test_data=test_data,
        feature_cols=feature_cols,
        seq_col=seq_col,
        batch_size=CFG['BATCH_SIZE'],
        device=device
    )
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission = create_submission(predictions)
    print("Prediction completed!")
    print(f"Prediction shape: {predictions.shape}")
    print(f"Prediction stats: min={predictions.min():.4f}, max={predictions.max():.4f}, mean={predictions.mean():.4f}")


def predict_test_data(test_data, feature_cols, seq_col, model_path=None, device="cuda"):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì œì¶œ íŒŒì¼ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    from main import CFG
    from data_loader import create_data_loaders
    
    # ëª¨ë¸ ë¡œë“œ
    model = load_trained_model(feature_cols, model_path, device)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë” ìƒì„±
    _, _, test_loader, _, _ = create_data_loaders(
        train_df=None,  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        val_df=None,    # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        test_df=test_data,
        feature_cols=feature_cols,
        seq_col=seq_col,
        target_col=None,  # í…ŒìŠ¤íŠ¸ì—ëŠ” íƒ€ê²Ÿ ì—†ìŒ
        batch_size=CFG['BATCH_SIZE']
    )
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = predict(
        model=model,
        test_loader=test_loader,
        device=device
    )
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission = create_submission(predictions)
    
    print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
    print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:")
    print(f"   - Shape: {predictions.shape}")
    print(f"   - Min: {predictions.min():.4f}")
    print(f"   - Max: {predictions.max():.4f}")
    print(f"   - Mean: {predictions.mean():.4f}")
    print(f"   - Std: {predictions.std():.4f}")
    
    return submission
