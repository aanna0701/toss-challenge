# GBDT Configuration for TOSS Challenge
# Supports both XGBoost and CatBoost models

# Data paths (pre-processed by dataset_split_and_preprocess.py)
data:
  train_t_path: "data/proc_train_t"  # Training data (80%, pre-processed)
  train_v_path: "data/proc_train_v"  # Validation data (10%, pre-processed)
  train_c_path: "data/proc_train_c"  # Calibration data (10%, pre-processed)
  temp_dir: "tmp"

# Training settings
training:
  # Always process fresh data - no caching

# Model selection (xgboost or catboost)
model:
  name: "xgboost"

# XGBoost configuration
xgboost:
  # n_estimators: 200
  # early_stopping_rounds: 20
  # max_depth: 8
  # learning_rate: 0.1
  # subsample: 0.8
  # colsample_bytree: 0.8
  # scale_pos_weight: null  # Set this value during runtime
  # gpu_id: 0
  # verbosity: 0
  # seed: 42
  # tree_method: gpu_hist
  # # MixUp augmentation settings
  # use_mixup: true
  # mixup_alpha: 0.6
  # mixup_ratio: 0.3
  n_estimators: 84
  early_stopping_rounds: 20
  max_depth: 5
  learning_rate: 0.13066341322939076
  subsample: 1.0
  colsample_bytree: 0.5108367911454451
  scale_pos_weight: null
  gpu_id: 0
  verbosity: 0
  seed: 42
  tree_method: gpu_hist
  use_mixup: true
  mixup_alpha: 0.1
  mixup_ratio: 0.2
  min_child_weight: 18
  gamma: 1.2673867800210414
  reg_alpha: 0.2763580304884297
  reg_lambda: 2.6758321672210155
  max_bin: 164
  calibration_method: sigmoid

# CatBoost configuration
catboost:
  # Model parameters
  iterations: 200
  learning_rate: 0.1
  depth: 8
  subsample: 1
  colsample_bylevel: 0.8
  task_type: "GPU"
  devices: "0"
  verbose: false
  early_stopping_rounds: 20
  thread_count: -1
  random_seed: 42
  bootstrap_type: "Bernoulli"  # Required when using subsample
  
  # MixUp augmentation settings
  use_mixup: false
  mixup_alpha: 0.3
  mixup_ratio: 0.5

# Preset configurations
presets:
  xgboost:
    model:
      name: "xgboost"
  
  catboost:
    model:
      name: "catboost"