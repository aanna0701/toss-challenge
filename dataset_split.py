#!/usr/bin/env python3
"""
ë°ì´í„°ì…‹ì„ 10-foldë¡œ ë¶„í• í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
- feat_e_3 missing ë°ì´í„°: ëª¨ë“  foldì— í• ë‹¹
- feat_e_3 available + clicked=1: ëª¨ë“  foldì— í• ë‹¹  
- feat_e_3 available + clicked=0: 10-foldë¡œ ë¶„í• 
- ê° foldë³„ë¡œ ë³„ë„ parquet íŒŒì¼ ìƒì„±: train_fold1.parquet, ..., train_fold10.parquet
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os
import gc
import pyarrow.parquet as pq
import argparse
import psutil

def create_classified_parquet_files(chunk_size=1000000):
    """ë¶„ë¥˜ëœ ë°ì´í„°ë¥¼ ë³„ë„ parquet íŒŒì¼ë¡œ ì €ì¥ (ì¦‰ì‹œ ì €ì¥ ë°©ì‹)"""
    print("ğŸ“Š ë¶„ë¥˜ëœ ë°ì´í„° íŒŒì¼ ìƒì„±/í™•ì¸ ì¤‘...")
    
    missing_file = 'data/missing_data.parquet'
    clicked_1_file = 'data/clicked_1_data.parquet'
    clicked_0_file = 'data/clicked_0_data.parquet'
    
    # ê¸°ì¡´ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
    print("  ğŸ“ ìƒˆë¡œìš´ ë¶„ë¥˜ íŒŒì¼ ìƒì„± ì¤‘...")
    print(f"  ğŸ”§ ì‚¬ìš©í•  chunk_size: {chunk_size:,} í–‰")
    
    # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ì¦‰ì‹œ ì €ì¥ 
    parquet_file = pq.ParquetFile('./data/train.parquet')
    total_rows = parquet_file.metadata.num_rows
    print(f"  ì „ì²´ ë°ì´í„°: {total_rows:,}ê°œ í–‰")
    
    # ê° ë¶„ë¥˜ë³„ ì¹´ìš´í„° ì´ˆê¸°í™”
    missing_count = 0
    clicked_1_count = 0
    clicked_0_count = 0
    
    # ì²« ë²ˆì§¸ ì²­í¬ë¡œ íŒŒì¼ ì´ˆê¸°í™”
    first_batch = True
    
    print("  ğŸ”„ ì²­í¬ ë‹¨ìœ„ë¡œ ë°ì´í„° ë¶„ë¥˜ ë° ì¦‰ì‹œ ì €ì¥ ì¤‘...")
    batch_count = 0
    
    for batch in parquet_file.iter_batches(batch_size=chunk_size):
        chunk = batch.to_pandas()
        print(f"  ğŸ“¦ ì²­í¬ {batch_count + 1} ë¡œë“œ ì™„ë£Œ: {len(chunk):,}ê°œ í–‰")
        
        # ë©”ëª¨ë¦¬ ìƒí™© ì¶œë ¥
        memory_info = psutil.virtual_memory()
        print(f"    ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB / {memory_info.total/(1024**3):.1f}GB)")
        
        # 1. feat_e_3 missing ë°ì´í„° ì²˜ë¦¬
        print(f"    ğŸ” feat_e_3 missing ë°ì´í„° ë¶„ë¥˜ ì¤‘...")
        missing_chunk = chunk[chunk['feat_e_3'].isna()]
        if len(missing_chunk) > 0:
            if first_batch:
                missing_chunk.to_parquet(missing_file, engine='pyarrow', compression='snappy', index=False)
            else:
                # ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€
                existing = pd.read_parquet(missing_file, engine='pyarrow')
                combined = pd.concat([existing, missing_chunk], ignore_index=True)
                combined.to_parquet(missing_file, engine='pyarrow', compression='snappy', index=False)
                del existing, combined
            missing_count += len(missing_chunk)
            print(f"      âœ… missing ë°ì´í„° ì €ì¥: {len(missing_chunk):,}ê°œ")
            
            # missing ë°ì´í„° ì €ì¥ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
            memory_info = psutil.virtual_memory()
            print(f"      ğŸ’¾ missing ì €ì¥ í›„ ë©”ëª¨ë¦¬: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB)")
        
        # missing_chunk ë©”ëª¨ë¦¬ í•´ì œ
        del missing_chunk
        gc.collect()
        
        # 2. feat_e_3 available + clicked=1 ë°ì´í„° ì²˜ë¦¬
        print(f"    ğŸ” feat_e_3 available + clicked=1 ë°ì´í„° ë¶„ë¥˜ ì¤‘...")
        clicked_1_chunk = chunk[(chunk['feat_e_3'].notna()) & (chunk['clicked'] == 1)]
        if len(clicked_1_chunk) > 0:
            if first_batch:
                clicked_1_chunk.to_parquet(clicked_1_file, engine='pyarrow', compression='snappy', index=False)
            else:
                # ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€
                existing = pd.read_parquet(clicked_1_file, engine='pyarrow')
                combined = pd.concat([existing, clicked_1_chunk], ignore_index=True)
                combined.to_parquet(clicked_1_file, engine='pyarrow', compression='snappy', index=False)
                del existing, combined
            clicked_1_count += len(clicked_1_chunk)
            print(f"      âœ… clicked=1 ë°ì´í„° ì €ì¥: {len(clicked_1_chunk):,}ê°œ")
            
            # clicked=1 ë°ì´í„° ì €ì¥ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
            memory_info = psutil.virtual_memory()
            print(f"      ğŸ’¾ clicked=1 ì €ì¥ í›„ ë©”ëª¨ë¦¬: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB)")
        
        # clicked_1_chunk ë©”ëª¨ë¦¬ í•´ì œ
        del clicked_1_chunk
        gc.collect()
        
        # 3. feat_e_3 available + clicked=0 ë°ì´í„° ì²˜ë¦¬
        print(f"    ğŸ” feat_e_3 available + clicked=0 ë°ì´í„° ë¶„ë¥˜ ì¤‘...")
        clicked_0_chunk = chunk[(chunk['feat_e_3'].notna()) & (chunk['clicked'] == 0)]
        if len(clicked_0_chunk) > 0:
            if first_batch:
                clicked_0_chunk.to_parquet(clicked_0_file, engine='pyarrow', compression='snappy', index=False)
            else:
                # ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€
                existing = pd.read_parquet(clicked_0_file, engine='pyarrow')
                combined = pd.concat([existing, clicked_0_chunk], ignore_index=True)
                combined.to_parquet(clicked_0_file, engine='pyarrow', compression='snappy', index=False)
                del existing, combined
            clicked_0_count += len(clicked_0_chunk)
            print(f"      âœ… clicked=0 ë°ì´í„° ì €ì¥: {len(clicked_0_chunk):,}ê°œ")
            
            # clicked=0 ë°ì´í„° ì €ì¥ í›„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
            memory_info = psutil.virtual_memory()
            print(f"      ğŸ’¾ clicked=0 ì €ì¥ í›„ ë©”ëª¨ë¦¬: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB)")
        
        # clicked_0_chunk ë©”ëª¨ë¦¬ í•´ì œ
        del clicked_0_chunk
        gc.collect()
        
        # ì›ë³¸ chunk ë©”ëª¨ë¦¬ í•´ì œ
        del chunk
        gc.collect()
        
        first_batch = False
        batch_count += 1
        
        # ëª¨ë“  ì²­í¬ì— ëŒ€í•´ ì§„í–‰ìƒí™© ì¶œë ¥
        processed = batch_count * chunk_size
        print(f"    ğŸ“Š ì²˜ë¦¬ ì§„í–‰: {processed:,}ê°œ / {total_rows:,}ê°œ ({processed/total_rows*100:.1f}%)")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ë©”ëª¨ë¦¬ ìƒí™© ì¶œë ¥
        memory_info = psutil.virtual_memory()
        print(f"    ğŸ’¾ ë©”ëª¨ë¦¬ ì •ë¦¬ í›„: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB / {memory_info.total/(1024**3):.1f}GB)")
        print("    " + "="*50)
    
    print(f"  ë°ì´í„° ë¶„í¬:")
    print(f"    - feat_e_3 missing: {missing_count:,}ê°œ")
    print(f"    - feat_e_3 available + clicked=1: {clicked_1_count:,}ê°œ")
    print(f"    - feat_e_3 available + clicked=0: {clicked_0_count:,}ê°œ")
    
    print(f"  âœ… ë¶„ë¥˜ íŒŒì¼ ì €ì¥ ì™„ë£Œ:")
    print(f"    - {missing_file}: {os.path.getsize(missing_file)/(1024*1024):.1f} MB")
    print(f"    - {clicked_1_file}: {os.path.getsize(clicked_1_file)/(1024*1024):.1f} MB")
    print(f"    - {clicked_0_file}: {os.path.getsize(clicked_0_file)/(1024*1024):.1f} MB")
    
    # ìµœì¢… ë¡œë“œí•˜ì—¬ ë°˜í™˜
    print("  ğŸ“‚ ìµœì¢… ë°ì´í„° ë¡œë“œ ì¤‘...")
    missing_data = pd.read_parquet(missing_file, engine='pyarrow')
    clicked_1_data = pd.read_parquet(clicked_1_file, engine='pyarrow')
    clicked_0_data = pd.read_parquet(clicked_0_file, engine='pyarrow')
    
    print(f"  âœ… ë¶„ë¥˜ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print(f"  ë°ì´í„° ë¶„í¬:")
    print(f"    - feat_e_3 missing: {len(missing_data):,}ê°œ")
    print(f"    - feat_e_3 available + clicked=1: {len(clicked_1_data):,}ê°œ")
    print(f"    - feat_e_3 available + clicked=0: {len(clicked_0_data):,}ê°œ")
    
    return missing_data, clicked_1_data, clicked_0_data

def create_fold_parquet_files(chunk_size=1000000):
    """ê° foldë³„ë¡œ ë³„ë„ parquet íŒŒì¼ ìƒì„± (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )"""
    print("ğŸš€ Foldë³„ parquet íŒŒì¼ ìƒì„± ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. ë¶„ë¥˜ëœ ë°ì´í„° ë¡œë“œ/ìƒì„±
    missing_data, clicked_1_data, clicked_0_data = create_classified_parquet_files(chunk_size)
    
    # 2. clicked=0 ë°ì´í„°ë¥¼ 10-foldë¡œ ë¶„í• 
    print("ğŸ”„ clicked=0 ë°ì´í„°ë¥¼ 10-foldë¡œ ë¶„í•  ì¤‘...")
    if len(clicked_0_data) > 0:
        n_clicked_0 = len(clicked_0_data)
        base_size = n_clicked_0 // 9
        remainder = n_clicked_0 % 9
        
        # ë°ì´í„°ë¥¼ ì„ê¸°
        clicked_0_data = clicked_0_data.sample(frac=1, random_state=42).reset_index(drop=True)
        
        # foldë³„ë¡œ ë¶„í• 
        fold_clicked_0_data = {}
        start_idx = 0
        
        for fold in range(1, 11):
            if fold <= 9:
                fold_size = base_size
                if fold == 9:
                    fold_size += remainder
                end_idx = start_idx + fold_size
                fold_clicked_0_data[fold] = clicked_0_data.iloc[start_idx:end_idx].copy()
                start_idx = end_idx
            else:
                # 10ë²ˆì§¸ fold: ëª¨ë“  clicked=0 ë°ì´í„°
                fold_clicked_0_data[fold] = clicked_0_data.copy()
    
    # 3. ê° foldë³„ parquet íŒŒì¼ ìƒì„±
    print("ğŸ’¾ Foldë³„ parquet íŒŒì¼ ìƒì„± ì¤‘...")
    fold_counts = {}
    
    for fold in range(1, 11):
        print(f"  ğŸ“ Fold {fold} ìƒì„± ì¤‘...")
        
        # í˜„ì¬ foldì˜ ë°ì´í„° êµ¬ì„±
        fold_data_list = []
        
        # 1. feat_e_3 missing ë°ì´í„° ì¶”ê°€ (ëª¨ë“  foldì— ê³µìœ )
        fold_data_list.append(missing_data.copy())
        
        # 2. feat_e_3 available + clicked=1 ë°ì´í„° ì¶”ê°€ (ëª¨ë“  foldì— ê³µìœ )
        fold_data_list.append(clicked_1_data.copy())
        
        # 3. feat_e_3 available + clicked=0 ë°ì´í„° ì¶”ê°€ (foldë³„ ë¶„í• )
        if len(clicked_0_data) > 0:
            fold_data_list.append(fold_clicked_0_data[fold].copy())
        
        # 4. ëª¨ë“  ë°ì´í„° ê²°í•© ë° ì„ê¸°
        fold_df = pd.concat(fold_data_list, ignore_index=True)
        fold_df = fold_df.sample(frac=1, random_state=42).reset_index(drop=True)
        
        # 5. parquet íŒŒì¼ë¡œ ì €ì¥
        filename = f'data/train_fold{fold}.parquet'
        fold_df.to_parquet(filename, engine='pyarrow', compression='snappy', index=False)
        
        fold_counts[fold] = len(fold_df)
        print(f"    âœ… {filename}: {len(fold_df):,}ê°œ í–‰, {os.path.getsize(filename)/(1024*1024):.1f} MB")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del fold_df, fold_data_list
        gc.collect()
    
    # 4. ìµœì¢… ìš”ì•½
    print(f"\nâœ… Foldë³„ parquet íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“Š ê° fold ë°ì´í„° ê°œìˆ˜:")
    for fold in range(1, 11):
        print(f"  Fold {fold}: {fold_counts[fold]:,}ê°œ")
    
    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
    for fold in range(1, 11):
        filename = f'train_fold{fold}.parquet'
        if os.path.exists(filename):
            file_size = os.path.getsize(filename) / (1024 * 1024)
            print(f"  {filename}: {file_size:.1f} MB")
    
    # 5. ì‚¬ìš© ì˜ˆì œ ìƒì„±
    create_usage_example()
    
    return fold_counts

def create_usage_example():
    """ì‚¬ìš© ì˜ˆì œ ìƒì„±"""
    example_code = '''#!/usr/bin/env python3
"""
Foldë³„ ë°ì´í„° ë¡œë”© ì‚¬ìš© ì˜ˆì œ
"""

import pandas as pd
from datetime import datetime

def load_fold_data(fold_number):
    """íŠ¹ì • fold ë°ì´í„° ë¡œë“œ"""
    filename = f'data/train_fold{fold_number}.parquet'
    print(f"ğŸ“Š Fold {fold_number} ë°ì´í„° ë¡œë”©: {filename}")
    
    start_time = datetime.now()
    data = pd.read_parquet(filename, engine='pyarrow')
    load_time = (datetime.now() - start_time).total_seconds()
    
    print(f"  âœ… ë¡œë”© ì™„ë£Œ: {len(data):,}ê°œ í–‰, {load_time:.2f}ì´ˆ")
    print(f"  ğŸ“Š ë°ì´í„° ë¶„í¬:")
    print(f"    - feat_e_3 missing: {data['feat_e_3'].isna().sum():,}ê°œ")
    print(f"    - clicked=0: {(data['clicked']==0).sum():,}ê°œ")
    print(f"    - clicked=1: {(data['clicked']==1).sum():,}ê°œ")
    
    return data

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Foldë³„ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    # ëª¨ë“  fold ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
    for fold in range(1, 11):
        data = load_fold_data(fold)
        print()
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del data

if __name__ == "__main__":
    main()
'''
    
    with open('load_fold_example.py', 'w', encoding='utf-8') as f:
        f.write(example_code)
    
    print(f"ğŸ“ ì‚¬ìš© ì˜ˆì œ ìƒì„±: load_fold_example.py")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='10-fold ë°ì´í„°ì…‹ ë¶„í• ')
    parser.add_argument('--chunk_size', type=int, default=1000000,
                       help='ì²˜ë¦¬í•  ì²­í¬ í¬ê¸° (ê¸°ë³¸ê°’: 1000000)')
    args = parser.parse_args()
    
    print("ğŸš€ ë°ì´í„°ì…‹ 10-fold ë¶„í•  ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”§ ì„¤ì •ëœ chunk_size: {args.chunk_size:,} í–‰")
    
    try:
        # Foldë³„ parquet íŒŒì¼ ìƒì„±
        fold_counts = create_fold_parquet_files(args.chunk_size)
        
        print(f"\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    main()