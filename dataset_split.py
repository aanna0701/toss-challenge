#!/usr/bin/env python3
"""
ë°ì´í„°ì…‹ì„ train/val/calë¡œ ë¶„í• í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
- ì „ì²´ ë°ì´í„°ë¥¼ 0.8 / 0.1 / 0.1 ë¹„ìœ¨ë¡œ ë¶„í• 
- train_t.parquet (80%), train_v.parquet (10%), train_c.parquet (10%)ë¡œ ì €ì¥
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os
import gc
import pyarrow.parquet as pq
import argparse
import psutil

def split_dataset(train_ratio=0.8, val_ratio=0.1, cal_ratio=0.1, random_state=42):
    """ë°ì´í„°ì…‹ì„ train/val/calë¡œ ë¶„í• """
    print("ğŸš€ ë°ì´í„°ì…‹ ë¶„í•  ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“Š ë¶„í•  ë¹„ìœ¨: train={train_ratio}, val={val_ratio}, cal={cal_ratio}")
    
    # ë¹„ìœ¨ ê²€ì¦
    assert abs(train_ratio + val_ratio + cal_ratio - 1.0) < 1e-6, "ë¹„ìœ¨ì˜ í•©ì´ 1ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤"
    
    # ì¶œë ¥ íŒŒì¼ëª…
    train_file = 'data/train_t.parquet'
    val_file = 'data/train_v.parquet'
    cal_file = 'data/train_c.parquet'
    
    # ê¸°ì¡´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if os.path.exists(train_file) and os.path.exists(val_file) and os.path.exists(cal_file):
        print("\nâš ï¸  ê¸°ì¡´ ë¶„í•  íŒŒì¼ë“¤ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
        print(f"  - {train_file}: {os.path.getsize(train_file)/(1024*1024):.1f} MB")
        print(f"  - {val_file}: {os.path.getsize(val_file)/(1024*1024):.1f} MB")
        print(f"  - {cal_file}: {os.path.getsize(cal_file)/(1024*1024):.1f} MB")
        
        response = input("\nğŸ”„ ê¸°ì¡´ íŒŒì¼ì„ ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() != 'y':
            print("âŒ ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            return
        print("\nğŸ“ ê¸°ì¡´ íŒŒì¼ì„ ë®ì–´ì”ë‹ˆë‹¤...")
    
    # 1. ì „ì²´ ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘...")
    memory_info = psutil.virtual_memory()
    print(f"  ğŸ’¾ ë¡œë“œ ì „ ë©”ëª¨ë¦¬: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB / {memory_info.total/(1024**3):.1f}GB)")
    
    start_time = datetime.now()
    all_data = pd.read_parquet('data/train.parquet', engine='pyarrow')
    load_time = (datetime.now() - start_time).total_seconds()
    
    total_rows = len(all_data)
    print(f"  âœ… ì „ì²´ ë°ì´í„°: {total_rows:,}ê°œ í–‰ ë¡œë“œ ì™„ë£Œ ({load_time:.2f}ì´ˆ)")
    
    memory_info = psutil.virtual_memory()
    print(f"  ğŸ’¾ ë¡œë“œ í›„ ë©”ëª¨ë¦¬: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB / {memory_info.total/(1024**3):.1f}GB)")
    
    # ë°ì´í„° ë¶„í¬ í™•ì¸
    clicked_1_count = (all_data['clicked'] == 1).sum()
    clicked_0_count = (all_data['clicked'] == 0).sum()
    print(f"\n  ğŸ“Š ì›ë³¸ ë°ì´í„° ë¶„í¬:")
    print(f"    - clicked=1: {clicked_1_count:,}ê°œ ({clicked_1_count/total_rows*100:.2f}%)")
    print(f"    - clicked=0: {clicked_0_count:,}ê°œ ({clicked_0_count/total_rows*100:.2f}%)")
    
    # 2. ë°ì´í„° ì„ê¸°
    print("\nğŸ”€ ë°ì´í„° ì„ê¸° ì¤‘...")
    all_data = all_data.sample(frac=1, random_state=random_state).reset_index(drop=True)
    print("  âœ… ë°ì´í„° ì„ê¸° ì™„ë£Œ")
    
    # 3. ë°ì´í„° ë¶„í• 
    print("\nâœ‚ï¸  ë°ì´í„° ë¶„í•  ì¤‘...")
    train_size = int(total_rows * train_ratio)
    val_size = int(total_rows * val_ratio)
    cal_size = total_rows - train_size - val_size  # ë‚˜ë¨¸ì§€ë¥¼ calì— í• ë‹¹
    
    print(f"  ğŸ“Š ë¶„í•  í¬ê¸°:")
    print(f"    - train: {train_size:,}ê°œ ({train_size/total_rows*100:.2f}%)")
    print(f"    - val:   {val_size:,}ê°œ ({val_size/total_rows*100:.2f}%)")
    print(f"    - cal:   {cal_size:,}ê°œ ({cal_size/total_rows*100:.2f}%)")
    
    # ë°ì´í„° ë¶„í• 
    train_data = all_data.iloc[:train_size].copy()
    val_data = all_data.iloc[train_size:train_size+val_size].copy()
    cal_data = all_data.iloc[train_size+val_size:].copy()
    
    # ì›ë³¸ ë°ì´í„° ë©”ëª¨ë¦¬ í•´ì œ
    del all_data
    gc.collect()
    
    memory_info = psutil.virtual_memory()
    print(f"  ğŸ’¾ ë¶„í•  í›„ ë©”ëª¨ë¦¬: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB / {memory_info.total/(1024**3):.1f}GB)")
    
    # 4. ê° split ë°ì´í„° ì €ì¥
    print("\nğŸ’¾ ë¶„í• ëœ ë°ì´í„° ì €ì¥ ì¤‘...")
    
    datasets = [
        ('train', train_data, train_file),
        ('val', val_data, val_file),
        ('cal', cal_data, cal_file)
    ]
    
    for split_name, data, filename in datasets:
        print(f"\n  ğŸ“ {split_name.upper()} ë°ì´í„° ì €ì¥ ì¤‘...")
        
        # ë°ì´í„° ë¶„í¬ í™•ì¸
        clicked_1 = (data['clicked'] == 1).sum()
        clicked_0 = (data['clicked'] == 0).sum()
        total = len(data)
        
        print(f"    ğŸ“Š ë°ì´í„° ë¶„í¬:")
        print(f"      - clicked=1: {clicked_1:,}ê°œ ({clicked_1/total*100:.2f}%)")
        print(f"      - clicked=0: {clicked_0:,}ê°œ ({clicked_0/total*100:.2f}%)")
        
        # íŒŒì¼ ì €ì¥
        start_time = datetime.now()
        data.to_parquet(filename, engine='pyarrow', compression='snappy', index=False)
        save_time = (datetime.now() - start_time).total_seconds()
        
        file_size = os.path.getsize(filename) / (1024 * 1024)
        print(f"    âœ… ì €ì¥ ì™„ë£Œ: {filename}")
        print(f"      - í¬ê¸°: {file_size:.1f} MB")
        print(f"      - ì‹œê°„: {save_time:.2f}ì´ˆ")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del data
        gc.collect()
        
        memory_info = psutil.virtual_memory()
        print(f"    ğŸ’¾ ì €ì¥ í›„ ë©”ëª¨ë¦¬: {memory_info.percent:.1f}% ({memory_info.used/(1024**3):.1f}GB / {memory_info.total/(1024**3):.1f}GB)")
    
    # 5. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 60)
    print("âœ… ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ!")
    print(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
    for _, _, filename in datasets:
        if os.path.exists(filename):
            file_size = os.path.getsize(filename) / (1024 * 1024)
            print(f"  {filename}: {file_size:.1f} MB")
    
    # 6. ì‚¬ìš© ì˜ˆì œ ìƒì„±
    create_usage_example()

def create_usage_example():
    """ì‚¬ìš© ì˜ˆì œ ìƒì„±"""
    example_code = '''#!/usr/bin/env python3
"""
ë¶„í• ëœ ë°ì´í„° ë¡œë”© ì‚¬ìš© ì˜ˆì œ
"""

import pandas as pd
from datetime import datetime

def load_split_data(split_type='train'):
    """ë¶„í• ëœ ë°ì´í„° ë¡œë“œ
    
    Args:
        split_type: 'train', 'val', 'cal' ì¤‘ í•˜ë‚˜
    """
    filename_map = {
        'train': 'data/train_t.parquet',
        'val': 'data/train_v.parquet',
        'cal': 'data/train_c.parquet'
    }
    
    if split_type not in filename_map:
        raise ValueError(f"split_typeì€ {list(filename_map.keys())} ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤")
    
    filename = filename_map[split_type]
    print(f"ğŸ“Š {split_type.upper()} ë°ì´í„° ë¡œë”©: {filename}")
    
    start_time = datetime.now()
    data = pd.read_parquet(filename, engine='pyarrow')
    load_time = (datetime.now() - start_time).total_seconds()
    
    print(f"  âœ… ë¡œë”© ì™„ë£Œ: {len(data):,}ê°œ í–‰, {load_time:.2f}ì´ˆ")
    print(f"  ğŸ“Š ë°ì´í„° ë¶„í¬:")
    print(f"    - clicked=0: {(data['clicked']==0).sum():,}ê°œ")
    print(f"    - clicked=1: {(data['clicked']==1).sum():,}ê°œ")
    
    return data

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ë¶„í• ëœ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # Train ë°ì´í„° ë¡œë”©
    print("\\n[TRAIN ë°ì´í„°]")
    train_data = load_split_data('train')
    
    # Validation ë°ì´í„° ë¡œë”©
    print("\\n[VALIDATION ë°ì´í„°]")
    val_data = load_split_data('val')
    
    # Calibration ë°ì´í„° ë¡œë”©
    print("\\n[CALIBRATION ë°ì´í„°]")
    cal_data = load_split_data('cal')
    
    print("\\nâœ… ëª¨ë“  ë°ì´í„° ë¡œë”© ì™„ë£Œ!")

if __name__ == "__main__":
    main()
'''
    
    with open('load_split_example.py', 'w', encoding='utf-8') as f:
        f.write(example_code)
    
    print(f"\nğŸ“ ì‚¬ìš© ì˜ˆì œ ìƒì„±: load_split_example.py")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë°ì´í„°ì…‹ì„ train/val/calë¡œ ë¶„í• ')
    parser.add_argument('--train-ratio', type=float, default=0.8, help='Train ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.8)')
    parser.add_argument('--val-ratio', type=float, default=0.1, help='Validation ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.1)')
    parser.add_argument('--cal-ratio', type=float, default=0.1, help='Calibration ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.1)')
    parser.add_argument('--random-state', type=int, default=42, help='ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)')
    args = parser.parse_args()
    
    try:
        split_dataset(
            train_ratio=args.train_ratio,
            val_ratio=args.val_ratio,
            cal_ratio=args.cal_ratio,
            random_state=args.random_state
        )
        
        print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    main()

